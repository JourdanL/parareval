{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "id_pairing": 5021, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of  biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface — some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists  choose either to increase or decrease the binding strength depending on  specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations is large,  it is not always feasible or affordable to conduct wet-lab assays to test all the viable mutations. Therefore, computational approaches are needed to guide the identification of desirable mutations via predicting the mutational effect on binding strength measured by the change in binding free energy ( ∆∆ G ).", "reference_paragraph": "Proteins rarely act alone and usually interact with other proteins to perform a diverse range of biological functions (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a type of immune system protein, recognize and bind to proteins on pathogens’ surfaces, eliciting immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Given the importance of protein-protein interactions in many biological processes, developing methods to modulate these interactions is critical. A common strategy to modulate protein-protein interactions is to mutate amino acids on the interface: some mutations enhance the strength of binding, while others weaken or even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may choose to increase or decrease binding strength depending on their specific goals. For example, enhancing the effect of a neutralizing antibody against a virus usually requires increasing the binding strength between the antibody and the viral protein. However, the combinatorial space of amino acid mutations is large, so it is not always feasible or affordable to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are needed to guide the identification of desirable mutations by predicting their mutational effects on binding strength, typically measured by the change in binding free energy ( ∆∆ G ).", "model_A_paragraph": "Proteins rarely function in isolation, instead, they typically interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to surface proteins and elicit immune responses by interacting with receptor proteins on immune cells (Lu et al., 2018). As protein-protein interactions underlie a multitude of biological functions, developing methods to modulate these interactions is crucial. One common approach to modulate protein-protein interactions is to mutate amino acids at the interface, which can either enhance or disrupt binding strength (Gram et al., 1992; Barderas et al., 2008). Biologists selectively increase or decrease binding strength depending on specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, increasing the binding strength between the antibody and the viral protein is often necessary. However, due to the vast combinatorial space of amino acid mutations, conducting wet-lab assays to test all viable mutations is not always feasible or affordable. Therefore, computational approaches are necessary to guide the identification of desirable mutations by predicting the mutational effect on binding strength, measured by the change in binding free energy (∆∆G).", "model_B_paragraph": "Proteins rarely act in isolation; instead, they interact with other proteins to orchestrate various biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, which are a type of immune system protein, recognize pathogens by binding to surface proteins and elicit immune responses through interactions with receptor proteins on immune cells (Lu et al., 2018). Given that protein-protein interactions govern numerous biological functions, developing methods to modulate these interactions is essential. A common approach to modulating protein-protein interactions involves mutating amino acids at the interaction interface—some mutations can enhance binding strength, while others may weaken or disrupt the interaction entirely (Gram et al., 1992; Barderas et al., 2008). Biologists either aim to increase or decrease binding strength based on specific objectives. For example, to enhance the efficacy of a neutralizing antibody against a virus, it is often necessary to increase the binding strength between the antibody and the viral protein. However, due to the vast combinatorial space of amino acid mutations, it is often impractical or cost-prohibitive to conduct wet-lab assays for all potential mutations. Consequently, computational approaches are needed to facilitate the identification of desirable mutations by predicting their effects on binding strength, as measured by changes in binding free energy (∆∆G).", "labels": ["Rewriting_light"], "instruction": "Lightly revise this paragraph to make it more clear and precise while keeping the academic style.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "id_pairing": 4570, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "reference_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. Appendix D will present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "model_A_paragraph": "An interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. This approach could be crucial when applying GBFS/A* with learned heuristics to path-finding instances with an enormous number of vertices. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with fewer tunable parameters than n can be designed.", "model_B_paragraph": "In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "labels": ["Content_deletion"], "instruction": "Delete the sentence about further study and the reference to section 2.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "extended_choice": "B"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "id_pairing": 2910, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, ( 2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).", "reference_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, andpublic language datasets) to evaluate DVRL in comparison to multiple benchmark methods. 3 public tabular datasets are (1) Blog, ( 2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100; 2 public language datasets are (11) Email Spam, (12) SMS Spam. Details can be found in the hyper-links.", "model_A_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods. The datasets include Blog, Adult, and Rossmann, as well as HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, and CIFAR-100 for images, and Email Spam and SMS Spam for language. Details can be found in the provided hyper-links.", "model_B_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods. Public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100; public language datasets are (11) Email Spam, (12) SMS Spam. Further details can be found in the provided hyper-links (in blue).", "labels": ["Concision"], "instruction": "Make the last sentence shorter.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "id_pairing": 2911, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o", "original_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, ( 2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).", "reference_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, andpublic language datasets) to evaluate DVRL in comparison to multiple benchmark methods. 3 public tabular datasets are (1) Blog, ( 2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100; 2 public language datasets are (11) Email Spam, (12) SMS Spam. Details can be found in the hyper-links.", "model_A_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods. Public tabular datasets are (1) Blog, (2) Adult, and (3) Rossmann; public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, and (10) CIFAR-100; public language datasets are (11) Email Spam and (12) SMS Spam. Details can be found in the provided hyper-links.", "model_B_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods. Public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100; public language datasets are (11) Email Spam, (12) SMS Spam. Dataset details are available in the provided hyperlinks.", "labels": ["Concision"], "instruction": "Make the last sentence shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "BJ49j43UH.B15bvYjiH.00", "id_pairing": 2912, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "coedit-xl", "original_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, ( 2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).", "reference_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, andpublic language datasets) to evaluate DVRL in comparison to multiple benchmark methods. 3 public tabular datasets are (1) Blog, ( 2) Adult, (3) Rossmann; 7 public image datasets are (4) HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100; 2 public language datasets are (11) Email Spam, (12) SMS Spam. Details can be found in the hyper-links.", "model_A_paragraph": "Datasets: We consider 12 public datasets (3 tabular, 7 image, 2 language) for comparison with benchmark methods: Blog, Adult, Rossmann (tabular); HAM 10000, MNIST, USPS, Flower, Fashion-MNIST, CIFAR-10, CIFAR-100 (image); Email Spam, SMS Spam (language). (Details can be found in the provided hyperlinks.)", "model_B_paragraph": "Datasets: We consider 12 public datasets (3 public tabular datasets, 7 public image datasets, and 2 public language datasets) to evaluate DVRL in comparison to multiple benchmark methods.public tabular datasets are (1) Blog, (2) Adult, (3) Rossmann; 7 public image datasets are HAM 10000, (5) MNIST, (6) USPS, (7) Flower, (8) Fashion-MNIST, (9) CIFAR-10, (10) CIFAR-100;public language datasets are (11) Email Spam, (12) SMS Spam. Detailsof the datasets can be found in the provided hyper-links (in blue).", "labels": ["Concision"], "instruction": "Make the last sentence shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "id_pairing": 5650, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o", "original_paragraph": "In practice, we do not have access to the true distribution p w . Rather, we are typically given a corpus { w p w n } N n =1 , whose instances we assume to be sampled i.i.d. from p w . The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98) ∆ that uses this corpus to approximate ∆ . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples  w p w ∼ p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence—present in both ∆ → and ∆ exp :", "reference_paragraph": "In practice, we do not have access to the true distribution p w . Rather, we are typically given a corpus { w p w n } N n =1 , whose instances we assume to be sampled i.i.d. from p w . The common approach to address this issue is thus to derive a statistical estimator (cid:98) ∆ that uses this corpus to approximate ∆ . There are two common strategies for building such estimators: Monte Carlo and plug-in estimation. Monte Carlo Estimation. Our i.i.d. assumption w.r.t. samples in { w p w n } Nn =1 allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence:", "model_A_paragraph": "With limited access to the true distribution p w in practice, we are usually provided a corpus { wpwn } with N samples, taken to be i.i.d. realizations from p w. To mitigate this issue, we typically develop statistical estimators (∆) using this given corpus to approximate the true divergence. Monte Carlo estimation is one popular approach when our i.i.d. assumption holds for samples wpwn ~ p w:\n\n3.2. Monte Carlo Estimation:\n\nOur i.i.d. assumption about the samples wpwn allows us to derive a Monte Carlo estimator for certain divergences, beginning with the forward KL divergence, applicable in both ∆ → and ∆ exp .", "model_B_paragraph": "In practice, we do not have access to the true distribution \\( p_w \\). Instead, we typically have a corpus \\(\\{w_i\\}_{i=1}^N\\) whose instances are assumed to be sampled independently and identically distributed (i.i.d.) from \\( p_w \\). A common way to address this limitation is to derive a statistical estimator \\(\\hat{\\Delta}\\) that uses this corpus to approximate \\(\\Delta\\). There are two main strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2 Monte Carlo Estimation Our i.i.d. assumption concerning samples \\( w_i \\sim p_w \\) allows us to derive a Monte Carlo estimator for certain divergences. We begin with the forward KL divergence, which is present in both \\(\\Delta_{\\rightarrow}\\) and \\(\\Delta_{\\text{exp}}\\).", "labels": ["Concision"], "instruction": "Fix formatting issues and simplify the wording of the paragraph.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes with additional modifications", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "id_pairing": 5651, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o-mini", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "In practice, we do not have access to the true distribution p w . Rather, we are typically given a corpus { w p w n } N n =1 , whose instances we assume to be sampled i.i.d. from p w . The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98) ∆ that uses this corpus to approximate ∆ . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples  w p w ∼ p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence—present in both ∆ → and ∆ exp :", "reference_paragraph": "In practice, we do not have access to the true distribution p w . Rather, we are typically given a corpus { w p w n } N n =1 , whose instances we assume to be sampled i.i.d. from p w . The common approach to address this issue is thus to derive a statistical estimator (cid:98) ∆ that uses this corpus to approximate ∆ . There are two common strategies for building such estimators: Monte Carlo and plug-in estimation. Monte Carlo Estimation. Our i.i.d. assumption w.r.t. samples in { w p w n } Nn =1 allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence:", "model_A_paragraph": "In practice, we do not have access to the true distribution \\( p_w \\). Instead, we typically have a corpus \\(\\{w_p, w_n\\}_{n=1}^{N}\\) that we assume is sampled independently and identically from \\( p_w \\). A common approach to this limitation is to derive a statistical estimator \\( \\hat{\\Delta} \\) that uses this corpus to approximate \\( \\Delta \\). There are two common strategies for creating such estimators: Monte Carlo estimation and plug-in estimation. 3.2. MONTE CARLO ESTIMATION Our assumption of independent and identically distributed samples \\( w_p \\sim p_w \\) allows us to create a Monte Carlo estimator for certain divergences. We begin with the forward KL divergence—present in both \\( \\Delta \\to \\) and \\( \\Delta_{exp} \\):", "model_B_paragraph": "In practice, we do not have access to the true distribution p(w). Instead, we are given a corpus {w^n, p_w^n}^N_{n=1}, whose instances are assumed to be sampled independently and identically distributed (i.i.d.) from p(w). To address this limitation, a common approach is to derive a statistical estimator ∆ that uses this corpus to approximate ∆. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. Monte Carlo Estimation Our i.i.d. assumption regarding samples w ~ p(w) allows us to derive a Monte Carlo estimator for certain divergences. We begin with the forward KL divergence, present in both ∆→ and ∆exp:", "labels": ["Concision"], "instruction": "Fix formatting issues and simplify the wording of the paragraph.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "p8yrWJS4W.eHA5NswPr.00", "id_pairing": 5652, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "coedit-xl", "original_paragraph": "In practice, we do not have access to the true distribution p w . Rather, we are typically given a corpus { w p w n } N n =1 , whose instances we assume to be sampled i.i.d. from p w . The common approach to address this shortcoming is (when possible) to derive a statistical estimator (cid:98) ∆ that uses this corpus to approximate ∆ . There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples  w p w ∼ p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence—present in both ∆ → and ∆ exp :", "reference_paragraph": "In practice, we do not have access to the true distribution p w . Rather, we are typically given a corpus { w p w n } N n =1 , whose instances we assume to be sampled i.i.d. from p w . The common approach to address this issue is thus to derive a statistical estimator (cid:98) ∆ that uses this corpus to approximate ∆ . There are two common strategies for building such estimators: Monte Carlo and plug-in estimation. Monte Carlo Estimation. Our i.i.d. assumption w.r.t. samples in { w p w n } Nn =1 allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence:", "model_A_paragraph": "In practice, we don't have access to the true distribution pw. Instead, we're typically given a corpus {wpwn}Nn=1, which we assume to be sampled i.i.d. from pw. To address this limitation, we often derive a statistical estimator ∆ that uses the corpus to approximate ∆. There are two common approaches: Monte Carlo estimation and plug-in estimation.", "model_B_paragraph": "In practice, we do not have access to the true distribution p w. Rather, we are typically given a corpus  w p w n  N n = 1, whose instances we assume to be sampled i.i.d. from p w. There are two common strategies for building such estimators: Monte Carlo estimation and plug-in estimation. 3.2. M ONTE C ARLO E STIMATION Our i.i.d. assumption w.r.t. samples w p w  p w allows us to derive a Monte Carlo estimator for certain divergences. We start with the forward KL divergence—present in both   and  exp :", "labels": ["Concision"], "instruction": "Fix formatting issues and simplify the wording of the paragraph.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "id_pairing": 4170, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "coedit-xl", "original_paragraph": "Study design For each task introduced in §5.1,  we construct a dataset where we duplicate one of the modalities as the two  input modalities, in addition to the original dataset. For example,  we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:", "reference_paragraph": "Study design For each task introduced in §5.1, in addition to the original dataset, we construct a dataset with two identical input modalities by copying one of the modalities. For example, when using the colored-and-gray-MNIST dataset, we predict the digit class using two identical gray-scale images. We train a multi-modal DNN on these dataset as explained below for each task:", "model_A_paragraph": "For each task introduced in §5.1, we create a new dataset by duplicating one modality as the two input modalities, along with the original dataset. In the case of MNIST, for instance, we predict digit classes using two identical grayscale images. Subsequently, we train a multi-modal Deep Neural Network (DNN) on each dataset of every task as explained below.", "model_B_paragraph": "Study design For each task introduced in 5.1, we construct a dataset where we duplicate one of the modalities as the two input modalities, in addition to the original dataset. For example, we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:", "labels": ["Rewriting_medium"], "instruction": "The wording in this paragraph is confusing, please improve the readability.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "id_pairing": 4171, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "Study design For each task introduced in §5.1,  we construct a dataset where we duplicate one of the modalities as the two  input modalities, in addition to the original dataset. For example,  we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:", "reference_paragraph": "Study design For each task introduced in §5.1, in addition to the original dataset, we construct a dataset with two identical input modalities by copying one of the modalities. For example, when using the colored-and-gray-MNIST dataset, we predict the digit class using two identical gray-scale images. We train a multi-modal DNN on these dataset as explained below for each task:", "model_A_paragraph": "Study design: For each task introduced in §5.1, we construct a dataset by duplicating one of the modalities so there are two identical input modalities, in addition to the original dataset. For instance, when predicting the digit class in MNIST, we use two identical gray-scale images. We then train a multi-modal DNN on each task's dataset as explained below:", "model_B_paragraph": "Study design For each task introduced in §5.1, we create a dataset by duplicating one of the modalities to serve as the two input modalities, in addition to the original dataset. For instance, in the case of MNIST, we predict the digit class using two identical gray-scale images. We then train a multi-modal DNN on each dataset for each task, as explained below:", "labels": ["Rewriting_medium"], "instruction": "The wording in this paragraph is confusing, please improve the readability.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.14", "id_pairing": 4172, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Study design For each task introduced in §5.1,  we construct a dataset where we duplicate one of the modalities as the two  input modalities, in addition to the original dataset. For example,  we predict the digit class using two identical gray-scale images in the case of MNIST. We train a multi-modal DNN on each dataset of each task as explained below:", "reference_paragraph": "Study design For each task introduced in §5.1, in addition to the original dataset, we construct a dataset with two identical input modalities by copying one of the modalities. For example, when using the colored-and-gray-MNIST dataset, we predict the digit class using two identical gray-scale images. We train a multi-modal DNN on these dataset as explained below for each task:", "model_A_paragraph": "Study design To facilitate each task introduced in §5.1, we create a dataset by duplicating one modality to serve as the two input modalities, in addition to the original dataset. For instance, in the case of MNIST, we predict the digit class using two identical gray-scale images. We then train a multi-modal DNN on each dataset for each task, as explained below:", "model_B_paragraph": "Study design: For each task described in §5.1, we create a dataset by duplicating one of the modalities and combining it with the original dataset as the two input modalities. For instance, in the MNIST task, we use two identical gray-scale images to predict the digit class. We then train a multi-modal deep neural network (DNN) on each dataset for each task as explained below.", "labels": ["Rewriting_medium"], "instruction": "The wording in this paragraph is confusing, please improve the readability.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "id_pairing": 1160, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "We observed the main effect of W ( F 2 , 22 = 25 . 3, p < 0 . 001, η 2 p = 0 . 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show the main effects . No significant interaction was observed.", "reference_paragraph": "We observed the main effect of W ( F 2 , 22 = 25 . 3, p < 0 . 001, η 2 p = 0 . 967) (Figure 4 (i)). The pair-wise comparisons showed that error rates increased with a decrease in W . The other parameters did not show the main effects. No significant interaction was observed.", "model_A_paragraph": "We observed a significant main effect of W (F(2, 22) = 25.3, p < 0.001, η²p = 0.967), as illustrated in Figure 4(i). Pairwise comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit main effects, and no significant interaction was observed.", "model_B_paragraph": "The significant main effect of W was identified (F(1, 22) = 25.3, p < 0.001, η²p = 0.967) (Figure 4(i)), revealing an increase in error rates as W decreased. Yet, no significant main effects were observed for the other parameters, and no interaction was noted (p > 0.05).", "labels": ["Rewriting_light"], "instruction": "Slightly revise for readability.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "id_pairing": 1161, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "coedit-xl", "original_paragraph": "We observed the main effect of W ( F 2 , 22 = 25 . 3, p < 0 . 001, η 2 p = 0 . 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show the main effects . No significant interaction was observed.", "reference_paragraph": "We observed the main effect of W ( F 2 , 22 = 25 . 3, p < 0 . 001, η 2 p = 0 . 967) (Figure 4 (i)). The pair-wise comparisons showed that error rates increased with a decrease in W . The other parameters did not show the main effects. No significant interaction was observed.", "model_A_paragraph": "We observed a significant main effect of W (F(2, 22) = 25.3, p < 0.001, η2p = 0.967; Figure 4(i)). Pairwise comparisons revealed that error rates increased as W decreased. In contrast, the other parameters did not exhibit main effects, and no significant interactions were observed.", "model_B_paragraph": "We observed the main effect of W ( F 2, 22 = 25. 3, p  0. 001,  2 p = 0. 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show any main effects. No significant interaction was observed.", "labels": ["Rewriting_light"], "instruction": "Slightly revise for readability.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.13", "id_pairing": 1162, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "We observed the main effect of W ( F 2 , 22 = 25 . 3, p < 0 . 001, η 2 p = 0 . 967) (Figure 4 (i)). Pair-wise comparisons showed that the error rates increased as W decreased. The other parameters did not show the main effects . No significant interaction was observed.", "reference_paragraph": "We observed the main effect of W ( F 2 , 22 = 25 . 3, p < 0 . 001, η 2 p = 0 . 967) (Figure 4 (i)). The pair-wise comparisons showed that error rates increased with a decrease in W . The other parameters did not show the main effects. No significant interaction was observed.", "model_A_paragraph": "We observed a main effect of W (F(2, 22) = 25.3, p < 0.001, η²p = 0.967) (Figure 4(i)). Pairwise comparisons indicated that error rates increased as W decreased. The other parameters did not show main effects. No significant interaction was observed.", "model_B_paragraph": "We observed the main effect of W (F(2, 22) = 25.3, p < 0.001, η²p = 0.967) (Figure 4(i)). Pairwise comparisons indicated that error rates increased as W decreased. The other parameters did not demonstrate main effects. Additionally, no significant interaction was observed.", "labels": ["Rewriting_light"], "instruction": "Slightly revise for readability.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_02"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "id_pairing": 3790, "pararev_annot": "annot_1", "pararev_annotator": "annotator_08", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "The easiest way to ensure m n = m n +1 , such that the acceptance probability remains nonzero, is to set the time step h = 0 . This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0 . Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of ∇ θ U ( θ n ) .", "reference_paragraph": "The easiest way to ensure m n = m n +1 , such that the acceptance probability remains nonzero, is to set the time step h = 0 . This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0 . Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. So far, we have not considered stochastic gradients, but this result includes them: it still holds if we substitute an arbitrary g n for ∇ θ U ( θ n ) .", "model_A_paragraph": "The easiest way to ensure m n = m n + 1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h  0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of   U (  n ).", "model_B_paragraph": "The easiest way to ensure m n = m n +1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error, because it will always be zero. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid for any choice of ∇ θ U ( θ n ).", "labels": ["Rewriting_medium"], "instruction": "Make the last sentence logical.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_medium": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "id_pairing": 3791, "pararev_annot": "annot_1", "pararev_annotator": "annotator_08", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o", "original_paragraph": "The easiest way to ensure m n = m n +1 , such that the acceptance probability remains nonzero, is to set the time step h = 0 . This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0 . Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of ∇ θ U ( θ n ) .", "reference_paragraph": "The easiest way to ensure m n = m n +1 , such that the acceptance probability remains nonzero, is to set the time step h = 0 . This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0 . Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. So far, we have not considered stochastic gradients, but this result includes them: it still holds if we substitute an arbitrary g n for ∇ θ U ( θ n ) .", "model_A_paragraph": "The easiest way to ensure m n = m n +1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially, however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error, rendering the Euler-Maruyama scheme unable to satisfy detailed balance.", "model_B_paragraph": "The easiest way to ensure m n = m n +1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially, however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error. Consequently, the Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid for any choice of ∇ θ U ( θ n ).", "labels": ["Rewriting_medium"], "instruction": "Make the last sentence logical.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_medium": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "JPHVd17f9N.nH2bI_9hXk.00", "id_pairing": 3792, "pararev_annot": "annot_1", "pararev_annotator": "annotator_08", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o-mini", "original_paragraph": "The easiest way to ensure m n = m n +1 , such that the acceptance probability remains nonzero, is to set the time step h = 0 . This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0 . Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid forany choice of ∇ θ U ( θ n ) .", "reference_paragraph": "The easiest way to ensure m n = m n +1 , such that the acceptance probability remains nonzero, is to set the time step h = 0 . This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0 . Thus, it is impossible to use the acceptance probability to monitor the discretisation error. The Euler-Maruyama scheme cannot satisfy detailed balance. So far, we have not considered stochastic gradients, but this result includes them: it still holds if we substitute an arbitrary g n for ∇ θ U ( θ n ) .", "model_A_paragraph": "The easiest way to ensure that m n = m n +1 while maintaining a nonzero acceptance probability is to set the time step h = 0. However, this renders the sampler ineffective. Although the Euler-Maruyama scheme approaches the true SDE trajectory as h approaches 0, Theorem 1 states that the acceptance probability is 0 for any h > 0. Consequently, it is impractical to employ the acceptance probability for monitoring discretisation errors. The Euler-Maruyama scheme fails to satisfy detailed balance, despite not yet having considered stochastic gradients: this result holds for any choice of ∇ θ U ( θ n ).", "model_B_paragraph": "The easiest way to ensure m n = m n +1, such that the acceptance probability remains nonzero, is to set the time step h = 0. This, however, makes the sampler useless. If we take the limit h → 0 instead, the Euler-Maruyama scheme gets arbitrarily close to the true SDE trajectory. Crucially however, per theorem 1, the acceptance probability remains 0 for any h > 0. Thus, it is impossible to use the acceptance probability to monitor the discretisation error effectively. The Euler-Maruyama scheme cannot satisfy detailed balance. Note that, so far, we have not considered stochastic gradients: this result is valid for any choice of ∇ θ U ( θ n ).", "labels": ["Rewriting_medium"], "instruction": "Make the last sentence logical.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "id_pairing": 5000, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model  [2]. A model with  higher  R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was consid- ered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.", "reference_paragraph": "Table 1 lists the results of model fitting using all 120 data points. We showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model along with the adjusted R 2 data [2]. A model with a higher adj. R 2 and lower AIC was defined as the better model. When the difference between the AIC s was higher than 2, the difference was worth considering; when it was higher than 10, it was considered significant. In Experiment 1, we set the starting position of the trials, and we excluded Eqs.and 6 from the comparison because the values of B in these models could not be obtained correctly.", "model_A_paragraph": "Table 1 presents the results of model fitting using all 120 data points, which we compared by examining the adjusted R² data and Akaike information criterion (AIC) values, as the number of constants included in the model varied [2]. A model with a higher R² and lower AIC was considered better, with differences in AIC values of more than 2 being worth considering and those exceeding 10 being deemed significant. In experiment 1, we controlled the starting position of trials, excluding Eq. 5 and Eq. 6 from the comparison due to the inability to accurately obtain the B values in these models.", "model_B_paragraph": "Table 1 lists the results of model fitting using all (120) data points. In addition to comparing the adjusted R² data, we also presented the Akaike information criterion (AIC) values due to the varying number of constants included in the model [2]. A model with a higher R² and a lower AIC is defined as the preferred model. Moreover, if the difference between the AIC values exceeds 2, this difference is worth considering, and if the difference exceeds 10, it is regarded as significant. In experiment 1, we established the starting position of the trials. Consequently, we excluded Eq. 5 and Eq. 6 from the comparison because the parameters of B in these models could not be obtained correctly.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Improve the linking between phrases.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "id_pairing": 5001, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o", "original_paragraph": "Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model  [2]. A model with  higher  R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was consid- ered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.", "reference_paragraph": "Table 1 lists the results of model fitting using all 120 data points. We showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model along with the adjusted R 2 data [2]. A model with a higher adj. R 2 and lower AIC was defined as the better model. When the difference between the AIC s was higher than 2, the difference was worth considering; when it was higher than 10, it was considered significant. In Experiment 1, we set the starting position of the trials, and we excluded Eqs.and 6 from the comparison because the values of B in these models could not be obtained correctly.", "model_A_paragraph": "Table 1 showcases the results of model fitting utilizing all 120 data points. To assess the model's performance, we compared the adjusted R² values and examined the Akaike Information Criterion (AIC) since these models contained varying numbers of constants [2]. We considered a model with a higher R² and lower AIC as the superior one. If the AIC difference surpassed 2, we deemed it worth considering, while a difference greater than 10 was regarded as significant. In Experiment 1, we specified the trials' starting positions. We omitted Eq. 5 and Eq. 6 from comparison due to the incorrect obtention of the B values in those models.", "model_B_paragraph": "Table 1 lists the results of model fitting using all (120) data points. In addition to comparing the adjusted R² data, we included the Akaike information criterion (AIC) values due to the different number of constants included in the model [2]. A model with higher R² and lower AIC was defined as the better model. If the difference between the AICs was greater than 2, it was worth considering, and if the difference exceeded 10, it was considered significant. During experiment 1, we set the starting position of the trials. Consequently, we excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Improve the linking between phrases.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.16", "id_pairing": 5002, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model  [2]. A model with  higher  R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was consid- ered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.", "reference_paragraph": "Table 1 lists the results of model fitting using all 120 data points. We showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model along with the adjusted R 2 data [2]. A model with a higher adj. R 2 and lower AIC was defined as the better model. When the difference between the AIC s was higher than 2, the difference was worth considering; when it was higher than 10, it was considered significant. In Experiment 1, we set the starting position of the trials, and we excluded Eqs.and 6 from the comparison because the values of B in these models could not be obtained correctly.", "model_A_paragraph": "Table 1 lists the results of model fitting using all (120) data points. Along with comparing the adjusted R 2 data, we showed the Akaike information criterion ( AIC ) values because of the different number of constants included in the model [2]. A model with higher R 2 and lower AIC was defined as the better model. If the difference between the AIC s was higher than 2, the difference was worth considering, and if is the difference was higher than 10, the difference was consid- ered significant. In experiment 1, we set the starting position of the trials. We excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.", "model_B_paragraph": "Table 1 lists the results of model fitting using all 120 data points, which are evaluated based on two key criteria: the adjusted R² data and the Akaike information criterion (AIC) values, the latter of which takes into account the different number of constants included in each model [2]. A model with a higher R² and lower AIC was defined as the better model. Furthermore, we adopted a threshold for considering the difference in AIC values, where a difference higher than 2 was worth considering and a difference higher than 10 was considered significant. In experiment 1, we set the starting position of the trials, and notably, we excluded Eq. 5 and Eq. 6 from the comparison because the values of B in these models could not be obtained correctly.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Improve the linking between phrases.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "id_pairing": 5030, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o-mini", "original_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and ” Enhance pointer precision ” setting was turned on to match the participant’s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in  full-screen mode.", "reference_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) and its refresh rate was set at 75 Hz. We used an optical mouse (Logitech gaming mouse, G-PPD-002WLr; 1600 DPI, and the mouse-cursor speed based on the OS setting was set to the middle of the slider in the control display and the “ Enhance pointer precision ” setting was turned on to match the usual settings of the participant.). The experimental system was implemented with Hot Soup Processor 3.6 and used in the full-screen mode 1 .", "model_A_paragraph": "The VZ249HR monitor (23.8” diagonal, 1920 × 1080 pixels) was set to a refresh rate of 75 Hz for our experiment. We employed a Logitech gaming mouse (G-PPD-002WLr; 1600 DPI) for input. The mouse-cursor speed was adjusted to the middle setting on the OS control display, and the \"Enhance pointer precision\" option was activated to align with the participants' normal settings. Our experimental setup utilized a Hot soup processor 3.6 and was operated in full-screen mode.", "model_B_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels), and its refresh rate was set at 75 Hz. For interaction, we used an optical mouse, specifically the Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed, adjusted via the OS setting, was set to the middle of the slider in the control display, while the ” Enhance pointer precision ” setting was turned on to match the participant’s usual settings. The experimental system was implemented with Hot Soup Processor 3.6 and utilized in full-screen mode.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Slightly revise the linking between phrases.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "id_pairing": 5031, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and ” Enhance pointer precision ” setting was turned on to match the participant’s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in  full-screen mode.", "reference_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) and its refresh rate was set at 75 Hz. We used an optical mouse (Logitech gaming mouse, G-PPD-002WLr; 1600 DPI, and the mouse-cursor speed based on the OS setting was set to the middle of the slider in the control display and the “ Enhance pointer precision ” setting was turned on to match the usual settings of the participant.). The experimental system was implemented with Hot Soup Processor 3.6 and used in the full-screen mode 1 .", "model_A_paragraph": "VZ249HR; 23.8” diagonal, 1920  1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and ” Enhance pointer precision ” setting was turned on to match the participant’s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.", "model_B_paragraph": "VZ249HR monitor with a 23.8” diagonal and 1920 × 1080 pixels resolution was used, set to a refresh rate of 75 Hz. We employed an optical mouse (Logitech gaming mouse, G-PPD-002WLr, 1600 DPI) and adjusted the mouse-cursor speed via the OS setting to the middle of the slider in the control display, with the \"Enhance pointer precision\" setting enabled to match the participant's usual settings. The experimental system was implemented using Hot soup processor 3.6 and run in full-screen mode.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Slightly revise the linking between phrases.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.08", "id_pairing": 5032, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) and its refresh rate was set at 75 Hz. We used an opticalmouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI). The mouse-cursor speed via the OS setting was set to the middle of the slider in the control display and ” Enhance pointer precision ” setting was turned on to match the participant’s usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in  full-screen mode.", "reference_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) and its refresh rate was set at 75 Hz. We used an optical mouse (Logitech gaming mouse, G-PPD-002WLr; 1600 DPI, and the mouse-cursor speed based on the OS setting was set to the middle of the slider in the control display and the “ Enhance pointer precision ” setting was turned on to match the usual settings of the participant.). The experimental system was implemented with Hot Soup Processor 3.6 and used in the full-screen mode 1 .", "model_A_paragraph": "VZ249HR; 23.8” diagonal, 1920 × 1080 pixels) with the refresh rate set at 75 Hz. We used an optical mouse, Logitech gaming mouse (G-PPD-002WLr; 1600 DPI), and adjusted the mouse-cursor speed via the OS setting to the middle of the slider in the control display with the “Enhance pointer precision” setting turned on to match the participant's usual settings. The experimental system was implemented with Hot soup processor 3.6 and used in full-screen mode.", "model_B_paragraph": "We employed a monitor, VZ249HR, with a 23.8” diagonal and a resolution of 1920 × 1080 pixels, set at a refresh rate of 75 Hz. Additionally, an optical mouse, specifically the Logitech gaming mouse (G-PPD-002WLr; 1600 DPI), was used. The mouse-cursor speed was adjusted via the OS setting to the middle of the slider in the control display, with the “Enhance pointer precision” setting turned on to match the participant’s usual settings. Furthermore, the experimental system was implemented using Hot soup processor 3.6 and run in full-screen mode.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Slightly revise the linking between phrases.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "id_pairing": 3880, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as  in experiment 1.", "reference_paragraph": "Figure 6 shows a schematic of the task. We did not set the starting position of the trial as a condition, unlike that in Experiment 1. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as that in Experiment 1.", "model_A_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, the starting position of the trial was strictly set. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.", "model_B_paragraph": "Figure 6 shows a schematic of the task. We controlled the starting position in Experiment 1, but not in Experiment 2. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.", "labels": ["Concision"], "instruction": "Make sentence 2 shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "id_pairing": 3881, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as  in experiment 1.", "reference_paragraph": "Figure 6 shows a schematic of the task. We did not set the starting position of the trial as a condition, unlike that in Experiment 1. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as that in Experiment 1.", "model_A_paragraph": "Except for this change, the task was the same as in experiment 1.", "model_B_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, we fixed the trial start position. In experiment 2, we allowed free trial starts within a rectangular area. The tasks were comparable in all other aspects.", "labels": ["Concision"], "instruction": "Make sentence 2 shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.20", "id_pairing": 3882, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial. In experiment 2, we did not set the starting position of the trial as a condition. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as  in experiment 1.", "reference_paragraph": "Figure 6 shows a schematic of the task. We did not set the starting position of the trial as a condition, unlike that in Experiment 1. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as that in Experiment 1.", "model_A_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, the starting position was strictly set. Experiment 2 varied the starting position, while the task remained the same otherwise.", "model_B_paragraph": "Figure 6 shows a schematic of the task. In experiment 1, we strictly set the starting position of the trial. In experiment 2, the starting position was not predetermined. The starting area was a rectangle, and the trials started by simply clicking an area once. Except for this change, the task was the same as in experiment 1.", "labels": ["Concision"], "instruction": "Make sentence 2 shorter.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_04"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "id_pairing": 5530, "pararev_annot": "annot_1", "pararev_annotator": "annotator_08", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Generalization of meta learning. The excess risk , as a metric of generalization ability of gradientbased meta learning has been analyzed recently [3,4,9,14,18,42]. The generalization of meta learninghas been studied in [27] in the context of mixed linear regression, where the focus is on investigatingwhen abundant tasks with small data can compensate for lack of tasks with big data. Generalization performance has also been studied in a relevant but different setting - representation based metalearning [13,16]. Information theoretical bounds have been proposed in [10,26], which bound thegeneralization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized metalearning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML,negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] shows that the optimal representation in representation-based meta learning isoverparameterized and provides sample complexity  for the method of moment estimator.", "reference_paragraph": "Generalization of meta learning. The excess risk , as a metric of generalization ability of nestedmeta learning has been analyzed recently [3,4,9,13,17,41]. Generalization performance has also been studied in a relevant but different setting - representation based meta learning [12,15]. Informationtheoretical generalization bounds have been proposed in [10,25], which bound the generalization errorin terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,14,18,32]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized meta learninghas attracted much attention. Bernacchia [6] suggests that in overparameterized MAML, negativelearning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [37] shows that the optimal representation in representation-based meta linear regression isoverparameterized and provides sample complexity bounds for the method of moment estimator.", "model_A_paragraph": "Generalization of meta learning has been analyzed recently, with the excess risk serving as a metric of generalization ability in gradient-based meta learning [3,4,9,14,18,42]. The generalization of meta learning has been studied in the context of mixed linear regression [27], where abundant tasks with small data can compensate for lack of tasks with big data. Information theoretical bounds have been proposed [10,26], which bound the generalization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. Additionally, overparameterized metalearning has attracted attention, with Bernacchia [6] suggesting that negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data, and Sun et al. [39] showing that the optimal representation in representation-based meta learning is overparameterized and provides sample complexity for the method of moment estimator.", "model_B_paragraph": "Generalization of meta learning has been analyzed recently, with the excess risk being used as a metric of generalization ability of gradient-based meta learning [3,4,9,14,18,42]. The generalization of meta learning has been studied in [27] in the context of mixed linear regression, where the focus is on investigating when abundant tasks with small data can compensate for lack of tasks with big data. Information theoretical bounds have been proposed in [10,26], which bound the generalization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. These works mostly focus on the case where the meta learning model is underparameterized. Recently, overparameterized metalearning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML, negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] shows that the optimal representation in representation-based meta learning is overparameterized and provides sample complexity for the method of moment estimator.", "labels": ["Content_deletion"], "instruction": "Remove a redundant sentence. Use clearer expression.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "extended_choice": "B"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "id_pairing": 5531, "pararev_annot": "annot_1", "pararev_annotator": "annotator_08", "model_A": "coedit-xl", "model_B": "gpt-4o-mini", "original_paragraph": "Generalization of meta learning. The excess risk , as a metric of generalization ability of gradientbased meta learning has been analyzed recently [3,4,9,14,18,42]. The generalization of meta learninghas been studied in [27] in the context of mixed linear regression, where the focus is on investigatingwhen abundant tasks with small data can compensate for lack of tasks with big data. Generalization performance has also been studied in a relevant but different setting - representation based metalearning [13,16]. Information theoretical bounds have been proposed in [10,26], which bound thegeneralization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized metalearning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML,negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] shows that the optimal representation in representation-based meta learning isoverparameterized and provides sample complexity  for the method of moment estimator.", "reference_paragraph": "Generalization of meta learning. The excess risk , as a metric of generalization ability of nestedmeta learning has been analyzed recently [3,4,9,13,17,41]. Generalization performance has also been studied in a relevant but different setting - representation based meta learning [12,15]. Informationtheoretical generalization bounds have been proposed in [10,25], which bound the generalization errorin terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,14,18,32]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized meta learninghas attracted much attention. Bernacchia [6] suggests that in overparameterized MAML, negativelearning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [37] shows that the optimal representation in representation-based meta linear regression isoverparameterized and provides sample complexity bounds for the method of moment estimator.", "model_A_paragraph": "Generalization of meta learning. The excess risk, as a metric of generalization ability of gradient-based meta learning has been analyzed recently [3,4,9,14,18,42]. The generalization of meta learninghas been studied in [27] in the context of mixed linear regression, where the focus is on investigatingwhen abundant tasks with small data can compensate for lack of tasks with big data. Generalization performance has also been studied in a relevant but different setting - representation based meta learning [13,16]. Information theoretical bounds have been proposed in [10,26], which bound thegeneralization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. Recently, overparameterized meta learning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML,negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] shows that the optimal representation in representation-based meta learning isoverparameterized and provides sample complexity for the method of moment estimator.", "model_B_paragraph": "Generalization of meta learning. The excess risk, as a metric of generalization ability of gradient-based meta learning has been analyzed recently [3,4,9,14,18,42]. The generalization of meta learning has been studied in [27] in the context of mixed linear regression, focusing on when abundant tasks with small data can compensate for a lack of tasks with big data. Generalization performance has also been studied in a relevant but different setting - representation-based meta learning [13,16]. Information theoretical bounds have been proposed in [10,26], which bound the generalization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized meta learning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML, a negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] show that the optimal representation in representation-based meta learning is overparameterized and provides sample complexity for the method of moment estimator.", "labels": ["Content_deletion"], "instruction": "Remove a redundant sentence. Use clearer expression.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "extended_choice": "A"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "x8CcXI4Ei.4yg90qT46L.01", "id_pairing": 5532, "pararev_annot": "annot_1", "pararev_annotator": "annotator_08", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o", "original_paragraph": "Generalization of meta learning. The excess risk , as a metric of generalization ability of gradientbased meta learning has been analyzed recently [3,4,9,14,18,42]. The generalization of meta learninghas been studied in [27] in the context of mixed linear regression, where the focus is on investigatingwhen abundant tasks with small data can compensate for lack of tasks with big data. Generalization performance has also been studied in a relevant but different setting - representation based metalearning [13,16]. Information theoretical bounds have been proposed in [10,26], which bound thegeneralization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized metalearning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML,negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [39] shows that the optimal representation in representation-based meta learning isoverparameterized and provides sample complexity  for the method of moment estimator.", "reference_paragraph": "Generalization of meta learning. The excess risk , as a metric of generalization ability of nestedmeta learning has been analyzed recently [3,4,9,13,17,41]. Generalization performance has also been studied in a relevant but different setting - representation based meta learning [12,15]. Informationtheoretical generalization bounds have been proposed in [10,25], which bound the generalization errorin terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta learning to provide a PAC-Bayes meta-population risk bound [1,14,18,32]. These works mostly focus on the case where the meta learning model is underparameterized; that is, the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized meta learninghas attracted much attention. Bernacchia [6] suggests that in overparameterized MAML, negativelearning rate in the inner loop is optimal during meta training for linear models with Gaussian data. Sun et al. [37] shows that the optimal representation in representation-based meta linear regression isoverparameterized and provides sample complexity bounds for the method of moment estimator.", "model_A_paragraph": "The generalization ability of gradient-based meta learning has been analyzed through the metric of excess risk in several recent works [3, 4, 9, 14, 18, 42]. Meta learning has also been investigated in the context of mixed linear regression [27], where the focus is on when abundant tasks with small data can compensate for a lack of tasks with large data. In representation-based meta learning [13, 16], information theoretical bounds have been proposed [10, 26] to bound the generalization error in terms of mutual information between input training data and meta-learning algorithm outputs. The PAC-Bayes framework has been extended to provide a PAC-Bayes meta-population risk bound [1, 15, 19, 34]. Most of these studies have centered on underparameterized meta learning models, where the number of meta training data from all tasks is larger than the dimension of the model parameter. Recent research, however, has shifted towards overparameterized meta learning. Bernacchia [6] suggests that the negative learning rate in the inner loop is optimal during meta training for linear models with Gaussian data in overparameterized MAML. Sun et al. [39] have shown that the optimal representation in representation-based meta learning is overparameterized and provides sample complexity for the method of moment estimator.", "model_B_paragraph": "The excess risk, as a metric of generalization ability of gradient-based meta-learning, has been analyzed recently [3,4,9,14,18,42]. The generalization of meta-learning has been studied in [27] in the context of mixed linear regression, where the focus is on investigating when abundant tasks with small data can compensate for a lack of tasks with big data. Generalization performance has also been studied in a relevant but different setting—representation-based meta-learning [13,16]. Information theoretical bounds have been proposed in [10,26], which bound the generalization error in terms of mutual information between the input training data and the output of the meta-learning algorithms. The PAC-Bayes framework has been extended to meta-learning to provide a PAC-Bayes meta-population risk bound [1,15,19,34]. These works mostly focus on the case where the meta-learning model is underparameterized, which means the total number of meta training data from all tasks is larger than the dimension of the model parameter. Recently, overparameterized meta-learning has attracted much attention. Bernacchia [6] suggests that in overparameterized MAML, a negative learning rate in the inner loop is optimal during meta-training for linear models with Gaussian data. Sun et al. [39] shows that the optimal representation in representation-based meta-learning is overparameterized and provides sample complexity for the method of moment estimator.", "labels": ["Content_deletion"], "instruction": "Remove a redundant sentence. Use clearer expression.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "No", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "extended_choice": "A"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "id_pairing": 4220, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "coedit-xl", "original_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation ( i.e ., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classiﬁcation performance.", "reference_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation ( i.e ., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the conditional positional encodings, CVPT-GAP can achieve much better image classiﬁcation performance.", "model_A_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation (i.e., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the conditional positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classiﬁcation performance.", "model_B_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classification. However, this token is not translation-invariant by design. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classification performance.", "labels": ["Concision"], "instruction": "Simplify the last sentence  by removing the notion of translation-equivariant  and just calling it conditional positional encodings.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "B", "extended_choice": "A"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "id_pairing": 4221, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation ( i.e ., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classiﬁcation performance.", "reference_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation ( i.e ., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the conditional positional encodings, CVPT-GAP can achieve much better image classiﬁcation performance.", "model_A_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation (i.e., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the conditional positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classiﬁcation performance.", "model_B_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token for classification (shown in Figure 1 (a) and (b)). The class token is not translation-invariant but can learn to be so. An alternative is to replace it with global average pooling (GAP), which is inherently translation-invariant. Combined with conditional positional encodings, CVPT-GAP is highly translation-invariant, leading to improved image classification performance.", "labels": ["Concision"], "instruction": "Simplify the last sentence  by removing the notion of translation-equivariant  and just calling it conditional positional encodings.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "c8pZvSp-5r.zd4IIIuixp.01", "id_pairing": 4222, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation ( i.e ., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the translation-equivariant positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classiﬁcation performance.", "reference_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation ( i.e ., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the conditional positional encodings, CVPT-GAP can achieve much better image classiﬁcation performance.", "model_A_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation (i.e., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with conditional positional encodings, CVPT-GAP is thus most translation-invariant and thus can achieve much better image classiﬁcation performance.", "model_B_paragraph": "In addition, both DeiT and ViT utilize an extra learnable class token to perform classiﬁcation (i.e., cls token shown in Figure 1 (a) and (b)). By design, the class token is not translation-invariant although it can learn to be so. A simple alternative is to directly replace it with a global average pooling (GAP), which is inherently translation-invariant, resulting in our CVPT-GAP. Together with the conditional positional encodings, CVPT-GAP is uttermost translation-invariant and thus can achieve much better image classiﬁcation performance.", "labels": ["Concision"], "instruction": "Simplify the last sentence  by removing the notion of translation-equivariant  and just calling it conditional positional encodings.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "None", "extended_choice": "B"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "id_pairing": 5250, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "gpt-4o-mini", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Meanwhile, a feature transformation can be applied to increase ﬁlter strength (Li et al., 2019b). Recap theinput of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48) , the inverse version of GCN can be written as:", "reference_paragraph": "Following GCN (Kipf & Welling, 2017), a feature transformation is applied to increase ﬁlter strength. Recap the GDN in Section 3.2, the inverse version of GCN can be written as:", "model_A_paragraph": "Meanwhile, a feature transformation enhances filter strength (Li et al., 2019b). As detailed in Section 3.2.2, the input of GDN consists of smoothed representations H (cid:48) and recovered structure A (cid:48); thus, the inverse version of GCN can be expressed as:", "model_B_paragraph": "Meanwhile, feature transformation can enhance filter strength (Li et al., 2019b). As outlined in Section 3.2.2, the input to GDN consists of smoothed representations and recovered structure, which can be inverted to form a GCN variant:", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make the text more concise by describing concepts more high-level.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "Rewriting_medium": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "id_pairing": 5251, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o", "original_paragraph": "Meanwhile, a feature transformation can be applied to increase ﬁlter strength (Li et al., 2019b). Recap theinput of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48) , the inverse version of GCN can be written as:", "reference_paragraph": "Following GCN (Kipf & Welling, 2017), a feature transformation is applied to increase ﬁlter strength. Recap the GDN in Section 3.2, the inverse version of GCN can be written as:", "model_A_paragraph": "A feature transformation can be applied to enhance filter strength (Li et al., 2019b). Recall, the GDN input consists of smoothed representations H and recovered structure A. The inverse of GCN can be expressed as:", "model_B_paragraph": "A feature transformation can enhance filter strength (Li et al., 2019b). Recapping Section 3.2.2, GDN inputs are smoothed representations \\(H'\\) and recovered structure \\(A'\\), with the inverse GCN written as:", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make the text more concise by describing concepts more high-level.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_medium": "None", "extended_choice": "B"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "g5N2H6sr7.6J3ec8Dl3p.01", "id_pairing": 5252, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Meanwhile, a feature transformation can be applied to increase ﬁlter strength (Li et al., 2019b). Recap theinput of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48) , the inverse version of GCN can be written as:", "reference_paragraph": "Following GCN (Kipf & Welling, 2017), a feature transformation is applied to increase ﬁlter strength. Recap the GDN in Section 3.2, the inverse version of GCN can be written as:", "model_A_paragraph": "Meanwhile, a feature transformation can be applied to increase filter strength (Li et al., 2019b). For example, to recap theinput of GDN in Section 3.2.2 is the smoothed representations H (cid:48) and the recovered structure A (cid:48), the inverse version of GCN can be written as:", "model_B_paragraph": "Meanwhile, a feature transformation can be applied to enhance filter strength (Li et al., 2019b). Recap the GDN input in Section 3.2.2 involves smoothed representations and recovered structure, enabling the inverse GCN formulation.", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make the text more concise by describing concepts more high-level.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "Rewriting_medium": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_05"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "id_pairing": 5020, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "coedit-xl", "original_paragraph": "Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of  biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface — some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists  choose either to increase or decrease the binding strength depending on  specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations is large,  it is not always feasible or affordable to conduct wet-lab assays to test all the viable mutations. Therefore, computational approaches are needed to guide the identification of desirable mutations via predicting the mutational effect on binding strength measured by the change in binding free energy ( ∆∆ G ).", "reference_paragraph": "Proteins rarely act alone and usually interact with other proteins to perform a diverse range of biological functions (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a type of immune system protein, recognize and bind to proteins on pathogens’ surfaces, eliciting immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Given the importance of protein-protein interactions in many biological processes, developing methods to modulate these interactions is critical. A common strategy to modulate protein-protein interactions is to mutate amino acids on the interface: some mutations enhance the strength of binding, while others weaken or even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may choose to increase or decrease binding strength depending on their specific goals. For example, enhancing the effect of a neutralizing antibody against a virus usually requires increasing the binding strength between the antibody and the viral protein. However, the combinatorial space of amino acid mutations is large, so it is not always feasible or affordable to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are needed to guide the identification of desirable mutations by predicting their mutational effects on binding strength, typically measured by the change in binding free energy ( ∆∆ G ).", "model_A_paragraph": "Proteins rarely function in isolation; they typically interact with other proteins to facilitate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surfaces and initiating immune responses through interactions with receptor proteins on immune cells (Lu et al., 2018). Given that protein-protein interactions determine numerous biological functions, developing methods to modulate these interactions is critical. A common approach to modulate protein-protein interactions involves mutating amino acids at the interaction interface—some mutations enhance binding strength, while others weaken or disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may aim to either increase or decrease binding strength based on specific objectives. For example, enhancing a neutralizing antibody's effect against a virus typically requires strengthening the binding between the antibody and viral protein. However, the vast combinatorial space of amino acid mutations makes it impractical and costly to test all viable mutations through wet-lab assays. Consequently, computational approaches are essential for guiding the identification of desirable mutations by predicting their effects on binding strength, as measured by changes in binding free energy (∆∆G).", "model_B_paragraph": "Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018).", "labels": ["Rewriting_light"], "instruction": "Lightly revise this paragraph to make it more clear and precise while keeping the academic style.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.00", "id_pairing": 5022, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Proteins rarely act alone but usually interact with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a kind of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Since proteinprotein interactions determine a large number of  biological functions, developing methods to modulate protein-protein interactions is critical. A typical way to modulate protein-protein interactions is to mutate amino acids on the interface — some mutations improve the strength of binding while others weaken and even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists  choose either to increase or decrease the binding strength depending on  specific goals. For example, if one would like to enhance the effect of a neutralizing antibody against a virus, it is usually necessary to increase the binding strength between the antibody and the viral protein. However, as the combinatorial space of amino acid mutations is large,  it is not always feasible or affordable to conduct wet-lab assays to test all the viable mutations. Therefore, computational approaches are needed to guide the identification of desirable mutations via predicting the mutational effect on binding strength measured by the change in binding free energy ( ∆∆ G ).", "reference_paragraph": "Proteins rarely act alone and usually interact with other proteins to perform a diverse range of biological functions (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For example, antibodies, a type of immune system protein, recognize and bind to proteins on pathogens’ surfaces, eliciting immune responses by interacting with the receptor protein of immune cells (Lu et al., 2018). Given the importance of protein-protein interactions in many biological processes, developing methods to modulate these interactions is critical. A common strategy to modulate protein-protein interactions is to mutate amino acids on the interface: some mutations enhance the strength of binding, while others weaken or even disrupt the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may choose to increase or decrease binding strength depending on their specific goals. For example, enhancing the effect of a neutralizing antibody against a virus usually requires increasing the binding strength between the antibody and the viral protein. However, the combinatorial space of amino acid mutations is large, so it is not always feasible or affordable to conduct wet-lab assays to test all viable mutations. Therefore, computational approaches are needed to guide the identification of desirable mutations by predicting their mutational effects on binding strength, typically measured by the change in binding free energy ( ∆∆ G ).", "model_A_paragraph": "Proteins primarily function through interactions with other proteins to regulate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, identify pathogens by binding to specific proteins on their surface and initiate immune responses upon interacting with the corresponding receptor proteins of immune cells (Lu et al., 2018). As protein-protein interactions underpin a multitude of biological functions, devising approaches to manipulate them is essential. One method to modify protein-protein interactions involves mutating interface amino acids; certain mutations enhance binding strength while others weaken or disrupt it (Gram et al., 1992; Barderas et al., 2008). Scientists opt to augment or diminish binding strength based on specific objectives. For example, to intensify the impact of a neutralizing antibody against a virus, it is often necessary to augment the binding strength between the antibody and the viral protein. However, given the vast combinatorial space of amino acid mutations, experiments to evaluate all viable mutations may not be feasible or cost-effective. Consequently, computational techniques are required to aid the identification of favorable mutations via predicting their effect on binding strength, estimated as the change in binding free energy (ΔΔG).", "model_B_paragraph": "Proteins rarely act independently, instead often interacting with other proteins to orchestrate biological processes (Alberts & Miake-Lye, 1992; Kastritis & Bonvin, 2013). For instance, antibodies, a type of immune system protein, recognize pathogens by binding to proteins on their surface and elicit immune responses through interactions with the receptor protein of immune cells (Lu et al., 2018). As protein-protein interactions underlie a significant proportion of biological functions, developing methods to modulate these interactions is crucial. One common approach to modulating protein-protein interactions is to mutate amino acids on the interface, with some mutations enhancing binding strength and others weakening or disrupting the interaction (Gram et al., 1992; Barderas et al., 2008). Biologists may aim to either increase or decrease binding strength depending on specific goals. For example, to enhance the effect of a neutralizing antibody against a virus, it is typically necessary to increase the binding strength between the antibody and the viral protein. However, the large combinatorial space of amino acid mutations makes it impractical or costly to conduct wet-lab assays to test all viable mutations, thus computational approaches are needed to guide the identification of desirable mutations by predicting the mutational effect on binding strength, as measured by the change in binding free energy (∆∆G).", "labels": ["Rewriting_light"], "instruction": "Lightly revise this paragraph to make it more clear and precise while keeping the academic style.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "id_pairing": 4571, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "coedit-xl", "original_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "reference_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. Appendix D will present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "model_A_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "model_B_paragraph": "Another future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog(n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "labels": ["Content_deletion"], "instruction": "Delete the sentence about further study and the reference to section 2.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "extended_choice": "A"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "vrvf56Ug_C.PgzrILJ_er.00", "id_pairing": 4572, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes, as mentioned in Section 2. Further study of this direction will be important, particularly when applying GBFS/A* with learned heuristics to path-finding instances with extremely many vertices. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "reference_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. Appendix D will present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "model_A_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. In Appendix D, we present an illustrative example where we can achieve polylog( n ) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "model_B_paragraph": "Another interesting future direction is to improve upper bounds on the pseudo-dimension by restricting heuristic functions to some classes. In Appendix D, we present an illustrative example where we can achieve polylog(n) upper bounds on the pseudo-dimension by assuming that heuristic functions with much fewer tunable parameters than n can be designed in an instance-specific manner.", "labels": ["Content_deletion"], "instruction": "Delete the sentence about further study and the reference to section 2.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "id_pairing": 2291, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Sequence-based models do not  predict ∆∆ G accurately for protein-protein binding in accordance with the discussion in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.", "reference_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding, as discussed in Section 2.2. Figure 3 shows the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.", "model_A_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding as discussed in Section 2.2. Figure 3 shows the distribution of per-complex correlation coefficients. For more results and discussion, see Section B of the appendix.", "model_B_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding, as discussed in Section 2.2. Figure 3 shows the distribution of per-complex correlation coefficients. For more results and discussion, see Section B of the appendix.", "labels": ["Rewriting_light", "Concision"], "instruction": "Simplify the English of this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "Concision": "A", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "id_pairing": 2292, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Sequence-based models do not  predict ∆∆ G accurately for protein-protein binding in accordance with the discussion in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.", "reference_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding, as discussed in Section 2.2. Figure 3 shows the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.", "model_A_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding, as discussed in Section 2.2. Figure 3 shows the distribution of per-complex correlation coefficients. For more results and discussion, see Section B of the appendix.", "model_B_paragraph": "Sequence-based models struggle to accurately predict ∆∆G for protein-protein binding, as discussed in Section 2.2. Figure 3 illustrates the distribution of per-complex correlation coefficients. For further information and discussion, please see Section B of the appendix.", "labels": ["Rewriting_light", "Concision"], "instruction": "Simplify the English of this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "id_pairing": 6010, "pararev_annot": "annot_2", "pararev_annotator": "annotator_02", "model_A": "gpt-4o", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we  discuss a toy system in which has many modes in section 5, then present our GFlowNet-based solution in section 4.", "reference_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we present our GFlowNet-based solution in section 4, then discuss a toy system which has many modes in section 5.", "model_A_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we present our GFlowNet-based solution in section 4, followed by a discussion of a toy system in section 5, which has many modes.", "model_B_paragraph": "In section 4, we present our GFlowNet-based solution. Previously, it has been demonstrated that GFlowNets are effective in handling multi-modal posteriors (Section 5). This capability is essential for our research, where multiple admissible structures can explain the observed data equally well.", "labels": ["Rewriting_light"], "instruction": "Revise this paragraph to present the sections in a coherent order.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "id_pairing": 6011, "pararev_annot": "annot_2", "pararev_annotator": "annotator_02", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we  discuss a toy system in which has many modes in section 5, then present our GFlowNet-based solution in section 4.", "reference_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we present our GFlowNet-based solution in section 4, then discuss a toy system which has many modes in section 5.", "model_A_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors, which is of particular interest to us given that many admissible structures can explain the observed data equally well. We then present our GFlowNet-based solution in section 4, and demonstrate its application in a toy system with many modes in section 5.", "model_B_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system which has many modes in section 4, then present our GFlowNet-based solution in section 5.", "labels": ["Rewriting_light"], "instruction": "Revise this paragraph to present the sections in a coherent order.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "CswFOyPyhT.FUeqrAFby.00", "id_pairing": 6012, "pararev_annot": "annot_2", "pararev_annotator": "annotator_02", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "coedit-xl", "original_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we  discuss a toy system in which has many modes in section 5, then present our GFlowNet-based solution in section 4.", "reference_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we present our GFlowNet-based solution in section 4, then discuss a toy system which has many modes in section 5.", "model_A_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors, which is of particular interest to us where many admissible structures can explain the observed data equally well. To illustrate this, we discuss a toy system with many modes in section 5. Then, we present our GFlowNet-based solution to tackle this issue in section 4.", "model_B_paragraph": "Previous work has shown GFlowNets are useful in settings with multi-modal posteriors. This is of particular interest to us where many admissible structures can explain the observed data equally well. Next, we discuss a toy system in which has many modes in section 5, then present our GFlowNet-based solution in section 4.", "labels": ["Rewriting_light"], "instruction": "Revise this paragraph to present the sections in a coherent order.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_light": "A", "extended_choice": "Tie"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "id_pairing": 2670, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "For all experiments we use an image size of 128 × 128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1 × 10 − 5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1 × 10 − 3 for the background module except for Figure 5, for which we use a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. We use gradient clipping with a maximum norm of 1.0. For Atari games, we ﬁnd it beneﬁcial to set α to be ﬁxed for the ﬁrst several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "reference_paragraph": "For all experiments we use an image size of 128 × 128 and a batch size of 12 to 16 depending on memory usage. For the foreground module, we use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1 × 10 − 5 except for Figure 5, for which we use a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. For the background module, we use the Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1 × 10 − 3 . We use gradient clipping with a maximum norm of 1.0. For Atari games, we ﬁnd it beneﬁcial to set α to be ﬁxed for the ﬁrst several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "model_A_paragraph": "We use an image size of 128 × 128 and a batch size of 12 to 16, depending on memory usage, for all experiments. The RMSProp optimizer with a learning rate of 1 × 10 − 5 is used for the foreground module, while the Adam optimizer with a learning rate of 1 × 10 − 3 is used for the background module, except for Figure 5, where a learning rate of 1 × 10 − 4 is used to ensure fair comparison with SPAIR. Gradient clipping is applied with a maximum norm of 1.0. For Atari games, we find it beneficial to set α to be fixed for the first several thousand steps, and then vary the actual value and number of steps for different games, allowing both the foreground and background modules to learn during the early stage of training.", "model_B_paragraph": "For all experiments, we use an image size of 128 × 128. The batch size ranges from 12 to 16, depending on memory usage. We use the RMSProp (Tieleman & Hinton, 2012) optimizer with a learning rate of 1 × 10 − 5 for the foreground module. For the background module, we utilize the Adam (Kingma & Ba, 2014) optimizer with a learning rate of 1 × 10 − 3, except for Figure 5, where we employ a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. We implement gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set α to be fixed for the first several thousand steps. Additionally, we vary the actual value and number of steps for different games. This approach allows both the foreground and background modules to learn during the early stage of training.", "labels": ["Rewriting_medium"], "instruction": "Split the long sentences into more concise sentences.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_medium": "A", "extended_choice": "Tie"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "id_pairing": 2671, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "coedit-xl", "model_B": "gpt-4o", "original_paragraph": "For all experiments we use an image size of 128 × 128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1 × 10 − 5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1 × 10 − 3 for the background module except for Figure 5, for which we use a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. We use gradient clipping with a maximum norm of 1.0. For Atari games, we ﬁnd it beneﬁcial to set α to be ﬁxed for the ﬁrst several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "reference_paragraph": "For all experiments we use an image size of 128 × 128 and a batch size of 12 to 16 depending on memory usage. For the foreground module, we use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1 × 10 − 5 except for Figure 5, for which we use a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. For the background module, we use the Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1 × 10 − 3 . We use gradient clipping with a maximum norm of 1.0. For Atari games, we ﬁnd it beneﬁcial to set α to be ﬁxed for the ﬁrst several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "model_A_paragraph": "For all experiments we use an image size of 128  128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1  10  5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1  10  3 for the background module. We use gradient clipping with a maximum norm of 1.0. For Atari games, we find it beneficial to set  to be fixed for the first several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "model_B_paragraph": "For all experiments, we use an image size of 128 × 128. The batch size varies from 12 to 16, depending on memory usage. We use the RMSProp (Tieleman & Hinton, 2012) optimizer with a learning rate of 1 × 10 − 5 for the foreground module. The Adam (Kingma & Ba, 2014) optimizer is used for the background module with a learning rate of 1 × 10 − 3, except for Figure 5, where we use a learning rate of 1 × 10 − 4 as in SPAIR, to ensure fair comparison. We employ gradient clipping with a maximum norm of 1.0. For Atari games, it is beneficial to set α to be fixed for the first several thousand steps. The actual value and number of steps are varied for different games. This strategy allows both the foreground and background modules to learn in the early stage of training.", "labels": ["Rewriting_medium"], "instruction": "Split the long sentences into more concise sentences.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "PcoXwm4jl.UxdreZBFz.00", "id_pairing": 2672, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "For all experiments we use an image size of 128 × 128 and a batch size of 12 to 16 depending on memory usage. We use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1 × 10 − 5 for the foreground module and Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1 × 10 − 3 for the background module except for Figure 5, for which we use a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. We use gradient clipping with a maximum norm of 1.0. For Atari games, we ﬁnd it beneﬁcial to set α to be ﬁxed for the ﬁrst several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "reference_paragraph": "For all experiments we use an image size of 128 × 128 and a batch size of 12 to 16 depending on memory usage. For the foreground module, we use the RMSProp (Tieleman & Hinton. (2012)) optimizer with a learning rate of 1 × 10 − 5 except for Figure 5, for which we use a learning rate of 1 × 10 − 4 as SPAIR to ensure fair comparison. For the background module, we use the Adam (Kingma & Ba (2014)) optimizer with a learning rate of 1 × 10 − 3 . We use gradient clipping with a maximum norm of 1.0. For Atari games, we ﬁnd it beneﬁcial to set α to be ﬁxed for the ﬁrst several thousand steps, and vary the actual value and number of steps for different games. This allows both the foreground as well as the background module to learn in the early stage of training.", "model_A_paragraph": "For experiments, an image size of 128 × 128 is used, with a batch size of 12 to 16, depending on memory usage. The RMSProp optimizer (Tieleman & Hinton, 2012) is employed for the foreground module with a learning rate of 1 × 10 − 5. For the background module, the Adam optimizer (Kingma & Ba, 2014) is utilized with a learning rate of 1 × 10 − 3, except for Figure 5, which is trained using a learning rate of 1 × 10 − 4, in accordance with SPAIR for fair comparison. Gradient clipping with a maximum norm of 1.0 is applied. For Atari games, setting α to a fixed value during the initial few thousand steps is beneficial, allowing both the foreground and background modules to learn at the onset of training. The actual value and number of steps can then be adjusted for different games.", "model_B_paragraph": "We use an image size of 128 × 128 and a batch size of 12 to 16, depending on memory usage, for all experiments. The RMSProp optimizer with a learning rate of 1 × 10 − 5 is used for the foreground module, while the Adam optimizer with a learning rate of 1 × 10 − 3 is used for the background module, except for Figure 5, where a learning rate of 1 × 10 − 4 is employed to ensure fair comparison. Additionally, gradient clipping with a maximum norm of 1.0 is applied. For Atari games, we set α to a fixed value for the first several thousand steps, and adjust the actual value and number of steps for different games, allowing both modules to learn in the early stages of training.", "labels": ["Rewriting_medium"], "instruction": "Split the long sentences into more concise sentences.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "id_pairing": 5310, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "RDE-Linear achieves performance comparable  to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations (Table 6 in the appendix). The reason might be  that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict ∆∆ G , laying the foundation for the more accurate RDE-Network.", "reference_paragraph": "RDE-Linear achieves comparable performance to Rosetta and outperforms some unsupervised learning baselines. While it does not surpass most baseline methods over the entire SKEMPI dataset, we observe that its performance is better when considering only single-point mutations (Table 6 in the appendix). This might be attributed to the fact that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Nevertheless, RDE-Linear demonstrates that using the basic statistics of the estimated rotamer density alone can predict ∆∆ G , which lays the foundation for the more accurate RDE-Network.", "model_A_paragraph": "RDE-Linear exhibits performance comparable to Rosetta and surpasses some unsupervised representation learning baselines. Although it does not outperform most baselines across the entire SKEMPI2 dataset, we observe that its performance is significantly better when considering only single-point mutations (Table 6 in the appendix). This may be attributed to the fact that simple linear models struggle to capture the non-linear relationships that dominate multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics of the estimated rotamer density alone can predict ΔΔG, thereby laying the groundwork for the more accurate RDE-Network.", "model_B_paragraph": "RDE-Linear matches Rosetta's performance and surpasses certain unsupervised representation learning benchmarks. Nevertheless, it does not surpass most baselines across the entire SKEMPI2 dataset. Notably, RDE-Linear performs significantly better when examining only single-point mutations (refer to Table 6 in the appendix). This potential shortcoming of simple linear models might stem from their limited ability to capture non-linear relationships inherent in multi-point mutations. However, RDE-Linear demonstrates that simple statistics of the calculated rotamer density estimation can accurately predict ∆∆ G, paving the way for more precise RDE-Network models.", "labels": ["Rewriting_light"], "instruction": "Improve the English in this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "id_pairing": 5311, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "RDE-Linear achieves performance comparable  to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations (Table 6 in the appendix). The reason might be  that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict ∆∆ G , laying the foundation for the more accurate RDE-Network.", "reference_paragraph": "RDE-Linear achieves comparable performance to Rosetta and outperforms some unsupervised learning baselines. While it does not surpass most baseline methods over the entire SKEMPI dataset, we observe that its performance is better when considering only single-point mutations (Table 6 in the appendix). This might be attributed to the fact that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Nevertheless, RDE-Linear demonstrates that using the basic statistics of the estimated rotamer density alone can predict ∆∆ G , which lays the foundation for the more accurate RDE-Network.", "model_A_paragraph": "RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Although it does not surpass most of the baselines across the entire SKEMPI2 dataset, its performance significantly improves when only single-point mutations are considered (see Table 6 in the appendix). This may be because simple linear models struggle to capture the nonlinear relationships that predominate in multi-point mutations. Nevertheless, RDE-Linear demonstrates that using simple statistics of the estimated rotamer density alone can predict ∆∆ G, laying the foundation for the more accurate RDE-Network.", "model_B_paragraph": "RDE-Linear achieves performance comparable to that of Rosetta and outperforms some unsupervised representation learning baselines. Although it does not surpass most of the baselines across the entire SKEMPI2 dataset, we find that its performance is significantly better when considering only single-point mutations (Table 6 in the appendix). The reason may be that simple linear models are incapable of capturing the non-linear relationships that dominate multi-point mutations. Nonetheless, RDE-Linear demonstrates that using simple statistics of the estimated rotamer density alone can predict ∆∆G, laying the foundation for the more accurate RDE-Network.", "labels": ["Rewriting_light"], "instruction": "Improve the English in this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.20", "id_pairing": 5312, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "coedit-xl", "original_paragraph": "RDE-Linear achieves performance comparable  to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations (Table 6 in the appendix). The reason might be  that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict ∆∆ G , laying the foundation for the more accurate RDE-Network.", "reference_paragraph": "RDE-Linear achieves comparable performance to Rosetta and outperforms some unsupervised learning baselines. While it does not surpass most baseline methods over the entire SKEMPI dataset, we observe that its performance is better when considering only single-point mutations (Table 6 in the appendix). This might be attributed to the fact that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Nevertheless, RDE-Linear demonstrates that using the basic statistics of the estimated rotamer density alone can predict ∆∆ G , which lays the foundation for the more accurate RDE-Network.", "model_A_paragraph": "RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Although it does not surpass most of the baselines across the entire SKEMPI2 dataset, we find that its performance is significantly improved when considering only single-point mutations (see Table 6 in the appendix). This could be attributed to the fact that simple linear models may struggle to capture the non-linear relationships prevalent in multi-point mutations. Nonetheless, RDE-Linear demonstrates that using simple statistics of the estimated rotamer density alone can effectively predict ∆∆G, thereby laying the groundwork for the more accurate RDE-Network.", "model_B_paragraph": "RDE-Linear achieves performance comparable to Rosetta and outperforms some unsupervised representation learning baselines. Though it does not outperform most of the baselines over the whole SKEMPI2 dataset, we find that its performance is much better when considering only single-point mutations. The reason might be that simple linear models cannot capture well the non-linear relationship dominating multi-point mutations. Anyway, RDE-Linear shows that using simple statistics of the estimated rotamer density alone can predict  G, laying the foundation for the more accurate RDE-Network.", "labels": ["Rewriting_light"], "instruction": "Improve the English in this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "id_pairing": 4580, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "In this work, we introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn’t have. When we add parameters, we outperform even standard ensembles on ImageNet with just 50% of the parameters. We believe that SuperWeight Ensembles represent a promising step forward in parameter-efficiency. Future work will include more deeply exploring architecture diversity; Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "reference_paragraph": "We introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing anytime prediction work by leveraging gradient information for parameter sharing. Our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, compared to prior work. When we add parameters, we outperform even deep ensembles on ImageNet with 50% of the parameters. We believe that SuperWeight Ensembles are a promising step forward in parameter-efficiency. Future work will include more deeply exploring architecture diversity; Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "model_A_paragraph": "We propose SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task by leveraging gradient information. Our automatic sharing approach improves single member performance by 2% compared to baselines and matches the performance of efficient ensembles in the low-parameter regime, while offering flexibility to adjust parameters. With 50% of the parameters, we outperform standard ensembles on ImageNet. We believe SuperWeight Ensembles represent a promising step forward in parameter-efficiency. Future work will explore architecture diversity, building on Gontijo-Lopes et al.'s (2021) findings on its contribution to ensemble diversity on challenging tasks.", "model_B_paragraph": "In this work, we introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles, which outperforms existing works on the anytime prediction task. Our automatic sharing improves single member performance by 2% compared to baselines and matches efficient ensemble performance in the low-parameter regime, while offering flexibility to adjust parameters. When adding parameters, SuperWeight Ensembles outperform standard ensembles on ImageNet with 50% fewer parameters. Future work will explore architecture diversity, as Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can contribute to ensemble diversity on challenging tasks.", "labels": ["Concision", "Rewriting_light"], "instruction": "Make this paragraph a bit more concise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Concision": "B", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "id_pairing": 4581, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "coedit-xl", "original_paragraph": "In this work, we introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn’t have. When we add parameters, we outperform even standard ensembles on ImageNet with just 50% of the parameters. We believe that SuperWeight Ensembles represent a promising step forward in parameter-efficiency. Future work will include more deeply exploring architecture diversity; Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "reference_paragraph": "We introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing anytime prediction work by leveraging gradient information for parameter sharing. Our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, compared to prior work. When we add parameters, we outperform even deep ensembles on ImageNet with 50% of the parameters. We believe that SuperWeight Ensembles are a promising step forward in parameter-efficiency. Future work will include more deeply exploring architecture diversity; Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "model_A_paragraph": "In this work, we introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. This approach enhances anytime prediction tasks by leveraging gradient information for effective parameter sharing, improving single member performance by 2% over baselines. SuperWeight Ensembles match efficient ensembles' performance in low-parameter regimes while offering flexibility to adjust parameters—an advantage not found in prior work. With additional parameters, they outperform standard ensembles on ImageNet using just 50% of the parameters. SuperWeight Ensembles represent a promising advancement in parameter efficiency, and future work will explore architecture diversity, as model architecture heterogeneity can significantly contribute to ensemble diversity on challenging tasks (Gontijo-Lopes et al., 2021).", "model_B_paragraph": "In this work, we introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. We find that our automatic sharing improves single member performance by 2% compared to the baselines. We also find that adding parameters improves performance by up to 2% when compared to standard ensembles on ImageNet with just 50% of the parameters.", "labels": ["Concision", "Rewriting_light"], "instruction": "Make this paragraph a bit more concise.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes with additional modifications", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "B", "Rewriting_light": "A", "extended_choice": "Tie"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "3686sm4Cs.AJMXMDLVn.03", "id_pairing": 4582, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o-mini", "original_paragraph": "In this work, we introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing works on the anytime prediction task by leveraging gradient information for effective parameter sharing. We find our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, while adding flexibility to adjust parameters which prior work doesn’t have. When we add parameters, we outperform even standard ensembles on ImageNet with just 50% of the parameters. We believe that SuperWeight Ensembles represent a promising step forward in parameter-efficiency. Future work will include more deeply exploring architecture diversity; Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "reference_paragraph": "We introduce SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing anytime prediction work by leveraging gradient information for parameter sharing. Our automatic sharing improves single member performance by 2% compared to the baselines. SuperWeight Ensembles also match performance of efficient ensembles in the low-parameter regime, compared to prior work. When we add parameters, we outperform even deep ensembles on ImageNet with 50% of the parameters. We believe that SuperWeight Ensembles are a promising step forward in parameter-efficiency. Future work will include more deeply exploring architecture diversity; Gontijo-Lopes et al. (2021) show that model architecture heterogeneity can be a key contributor to ensemble diversity on challenging tasks.", "model_A_paragraph": "This study introduces SuperWeight Ensembles, an efficient method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles surpass existing approaches on the anytime prediction task by utilizing gradient information for advanced parameter sharing. Our method enhances single member performance by 2% over baselines and matches the performance of efficient ensembles in the low-parameter regime. SuperWeight Ensembles outperform standard ensembles on ImageNet with half the parameters. We conclude that SuperWeight Ensembles signify a significant advancement in parameter-efficiency. Further research will investigate architecture diversity, as demonstrated by Gontijo-Lopes et al. (2021) to enhance ensemble performance on difficult tasks.", "model_B_paragraph": "In this work, we introduced SuperWeight Ensembles, a method for parameter sharing in heterogeneous ensembles. SuperWeight Ensembles outperform existing approaches on the anytime prediction task by leveraging gradient information for effective parameter sharing. Our automatic sharing enhances single member performance by 2% compared to the baselines. SuperWeight Ensembles also match the performance of efficient ensembles in the low-parameter regime while providing flexibility to adjust parameters, a feature lacking in prior work. With added parameters, we surpass standard ensembles on ImageNet while using only 50% of the parameters. We believe SuperWeight Ensembles represent a significant advancement in parameter efficiency. Future work will explore architecture diversity in depth, as Gontijo-Lopes et al. (2021) indicate that model architecture heterogeneity can significantly contribute to ensemble diversity on challenging tasks.", "labels": ["Concision", "Rewriting_light"], "instruction": "Make this paragraph a bit more concise.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_light": "A", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "id_pairing": 4110, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "gpt-4o", "model_B": "coedit-xl", "original_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP  to create the action-summary to be used in the subsequent utility network.", "reference_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then, the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015). Another 2-layer MLP follows this to create the action set summary to be used in the following utility network.", "model_A_paragraph": "The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then, the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015). This is followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.", "model_B_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP to create the action-summary to be used in the subsequent utility network.", "labels": ["Rewriting_light"], "instruction": "Split this paragraph into smaller and more focused points.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_light": "A", "extended_choice": "Tie"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "id_pairing": 4111, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP  to create the action-summary to be used in the subsequent utility network.", "reference_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then, the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015). Another 2-layer MLP follows this to create the action set summary to be used in the following utility network.", "model_A_paragraph": "1:\nPoint 1: The raw action representations are first processed by a 2-layer MLP with ReLU activation. (Huang et al., 2015)\nPoint 2: The output of the MLP is then passed to a bidirectional 2-layer LSTM.\nPoint 3: The bidirectional LSTM generates the action-summary to be utilized in the subsequent utility network.", "model_B_paragraph": "The processing of raw action representations involves several steps. First, the representations are passed through a 2-layer MLP with ReLU activation. Next, the output is fed into a 2-layer bidirectional LSTM (Huang et al., 2015). Finally, the output of the LSTM is processed by another 2-layer MLP to create the action-summary, which is then used in the subsequent utility network.", "labels": ["Rewriting_light"], "instruction": "Split this paragraph into smaller and more focused points.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes with additional modifications", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_light": "B", "extended_choice": "Tie"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.22", "id_pairing": 4112, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015) followed by another 2-layer MLP  to create the action-summary to be used in the subsequent utility network.", "reference_paragraph": "Bi-LSTM : The raw action representations of candidate actions are passed on to the 2-layer MLP followed by ReLU. Then, the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015). Another 2-layer MLP follows this to create the action set summary to be used in the following utility network.", "model_A_paragraph": "The raw action representations of candidate actions are first passed through a 2-layer MLP followed by ReLU. The output of the MLP is then processed by a 2-layer bidirectional LSTM (Huang et al., 2015). Finally, the output of the LSTM is fed into another 2-layer MLP to create the action-summary. This action-summary is then used in the subsequent utility network.", "model_B_paragraph": "Bi-LSTM: The raw action representations of candidate actions are first passed on to a 2-layer MLP followed by ReLU. Next, the output of the MLP is processed by a 2-layer bidirectional LSTM (Huang et al., 2015). Finally, another 2-layer MLP creates the action-summary to be used in the subsequent utility network.", "labels": ["Rewriting_light"], "instruction": "Split this paragraph into smaller and more focused points.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_light": "A", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "id_pairing": 6020, "pararev_annot": "annot_1", "pararev_annotator": "annotator_06", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "reference_paragraph": "Figure 3 is an example of using Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value. The main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. For a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "model_A_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "model_B_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation.", "labels": ["Concision", "Rewriting_light"], "instruction": "Remove the second sentence and make the paragraph more concise", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_light": "None", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "id_pairing": 6021, "pararev_annot": "annot_1", "pararev_annotator": "annotator_06", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "reference_paragraph": "Figure 3 is an example of using Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value. The main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. For a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "model_A_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "model_B_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation.", "labels": ["Concision", "Rewriting_light"], "instruction": "Remove the second sentence and make the paragraph more concise", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_light": "None", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "NAxP0iFmBr.5QBuYp8GH.04", "id_pairing": 6022, "pararev_annot": "annot_1", "pararev_annotator": "annotator_06", "model_A": "gpt-4o-mini", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. There is a breakdown of Eq. 6 just below it. But just in case if it seems too obscure, here is a more intuitive description of Eq. The CTCR is incentivized by the Shapley Value, so the main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "reference_paragraph": "Figure 3 is an example of using Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value. The main idea is that the overall optimality needs to also account for the optimality of every possible sub-formation. For a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "model_A_paragraph": "Figure 3 is an example of how to plug numbers into Eq. 6 to compute CTCR for each of the three cameras. The CTCR is incentivized by the Shapley Value, meaning the overall optimality must also account for the optimality of every possible sub-formation. In the context of an active HPE task, for a camera agent to receive the highest CTCR possible, its current position and view must be optimal both in terms of its current formation and any sub-formation possible.", "model_B_paragraph": "Figure 3 illustrates computing CTCR for each camera using Eq. 6. The breakdown of Eq. 6 is provided beneath it. The CTCR is determined by the Shapley Value, emphasizing the importance of optimality for every possible sub-formation in the context of an active HPE task. For a camera agent to obtain the highest CTCR, its position and view must be optimal within the current formation and any potential sub-formations.", "labels": ["Concision", "Rewriting_light"], "instruction": "Remove the second sentence and make the paragraph more concise", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "id_pairing": 3410, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "coedit-xl", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals  not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.", "reference_paragraph": "A critical problem in the ﬁeld of post hoc explainability is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some by game theoretic notions, and some by obtaining clean visualizations. This fragmentation of goals causes not only an inconsistent conceptual understanding of explanations but also the practical challenge of not knowing which method to use when.", "model_A_paragraph": "A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.", "model_B_paragraph": "The literature on post hoc explanations suffers from a lack of a shared objective among methods, leading to confusion. Some methods aim for function approximation, others utilize Shapley-Aumann values from game theory, and some are ad hoc for clear visualizations. This disparity in goals impedes a clear conceptual comprehension and presents a practical dilemma of choosing the appropriate method.", "labels": ["Concision"], "instruction": "Make as concise as possible the paragraph, removing any ideas that are not essential. Use a clearer word choice.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "id_pairing": 3411, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o-mini", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals  not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.", "reference_paragraph": "A critical problem in the ﬁeld of post hoc explainability is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some by game theoretic notions, and some by obtaining clean visualizations. This fragmentation of goals causes not only an inconsistent conceptual understanding of explanations but also the practical challenge of not knowing which method to use when.", "model_A_paragraph": "A key problem in post hoc explanation literature is the lack of a common foundational goal among methods. Some focus on function approximation, others use game theoretic concepts like Shapley-Aumann values, while some prioritize clear visualizations. This fragmentation hinders coherent understanding and creates practical challenges in selecting appropriate methods.", "model_B_paragraph": "The literature on post hoc explanations lacks a unifying goal, with methods driven by diverse objectives such as function approximation, game theory, or visualization. This fragmentation hinders a coherent understanding of explainability and creates practical challenges in method selection.", "labels": ["Concision"], "instruction": "Make as concise as possible the paragraph, removing any ideas that are not essential. Use a clearer word choice.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "wNQ4_8Ym_c.1vd_qn2D93.00", "id_pairing": 3412, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "A critical problem in the literature on post hoc explanations is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some use game theoretic notions such as Shapley-Aumann values, and some are ad hoc, driven by the goal of obtaining clean visualizations. Such fragmentation of goals  not only prevents a coherent conceptual understanding of post hoc explainability but also causes the practical challenge of not knowing which method to use when.", "reference_paragraph": "A critical problem in the ﬁeld of post hoc explainability is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some by game theoretic notions, and some by obtaining clean visualizations. This fragmentation of goals causes not only an inconsistent conceptual understanding of explanations but also the practical challenge of not knowing which method to use when.", "model_A_paragraph": "A critical issue in post hoc explanations is the lack of a unified foundational goal among methods, which hinders both conceptual understanding and practical application.", "model_B_paragraph": "A key issue in post hoc explanation research is the absence of a unified goal among methods. Some approaches focus on function approximation, while others employ game theory or aim for visually appealing results. This fragmentation hinders a coherent understanding of post hoc explainability and makes it difficult to choose the most suitable method.", "labels": ["Concision"], "instruction": "Make as concise as possible the paragraph, removing any ideas that are not essential. Use a clearer word choice.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_08"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "id_pairing": 3510, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is  between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "reference_paragraph": "In Experiment 1, we showed that the notch increases the pointing movement time under specific scenarios. Further, we found that participants moved the cursor based on two main strategies when the notch is placed between the start area and the target: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In Experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "model_A_paragraph": "In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). Finally, in experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "model_B_paragraph": "In experiment 1, we demonstrated that the notch prolongs pointing movement time under certain conditions. Participants employed two primary cursor navigation strategies when the notch was situated between targets: (i) following the edge (along-strategy), and (ii) circumventing the notch (avoid-strategy). In experiment 2, we explored which of these strategies proved more effective under the given specifications, allowing cursor entry into the notch.", "labels": ["Rewriting_medium"], "instruction": "Make this paragraph more logical and precise.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_06"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "id_pairing": 3511, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is  between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "reference_paragraph": "In Experiment 1, we showed that the notch increases the pointing movement time under specific scenarios. Further, we found that participants moved the cursor based on two main strategies when the notch is placed between the start area and the target: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In Experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "model_A_paragraph": "In experiment 1, we demonstrated that the notch increases pointing movement time under specific conditions. Notably, when the notch is positioned between the targets, participants employed two primary strategies: (i) moving the cursor along the edge (along-strategy) and (ii) avoiding the notch (avoid-strategy). Building on these findings, experiment 2 aimed to determine which of these strategies is more effective in the current specification, where the cursor is allowed to enter the notch.", "model_B_paragraph": "In experiment 1, we found that the notch prolongs pointing movement time in specific situations. Additionally, when the notch is situated between targets, participants employed two primary strategies: moving the cursor along the edge (along-strategy) or avoiding the notch (avoid-strategy). In experiment 2, we aimed to determine which of these strategies is more effective in the current setup, which permits the cursor to enter the notch.", "labels": ["Rewriting_medium"], "instruction": "Make this paragraph more logical and precise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_06"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.17", "id_pairing": 3512, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "In experiment 1, we showed that the notch increases the pointing movement time in specific situations. Furthermore, when the notch is  between the targets, participants moved the cursor with two main strategies: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "reference_paragraph": "In Experiment 1, we showed that the notch increases the pointing movement time under specific scenarios. Further, we found that participants moved the cursor based on two main strategies when the notch is placed between the start area and the target: (i) to move the cursor along the edge (along-strategy) and (ii) to avoid the notch (avoid-strategy). In Experiment 2, we investigated which of the above strategies is preferable in the current specification that allows the cursor to enter the notch.", "model_A_paragraph": "In experiment 1, we demonstrated that the presence of a notch increases pointing movement time in certain situations. When the notch is situated between the targets, participants adopted two primary strategies for moving the cursor: (i) moving the cursor along the edge, termed the 'along-strategy,' and (ii) avoiding the notch, termed the 'avoid-strategy.' In experiment 2, we examined which strategy is preferable under conditions that permit the cursor to enter the notch.", "model_B_paragraph": "In Experiment 1, we demonstrated that the presence of the notch increases the pointing movement time under specific conditions. Additionally, when the notch is positioned between the targets, participants employed two primary cursor movement strategies: (i) moving the cursor along the edge (along-strategy) and (ii) circumventing the notch (avoid-strategy). In Experiment 2, we examined which of these strategies is more effective when the cursor is permitted to enter the notch.", "labels": ["Rewriting_medium"], "instruction": "Make this paragraph more logical and precise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_06"}
{"id_paragraph": "YkiRt7L93m.jgDbnUD7s.04", "id_pairing": 1600, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o", "original_paragraph": "We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some  target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation which gives unique, interpretable weights in a setting of regular probability measures. For general probability measures, we construct our projection by ﬁrst creating a regular tangent space through applying barycentric projection to optimal transport plans. Our application to evaluating the ﬁrst- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010) demonstrates the method’s efﬁciency and the necessity to have a method that is applicable for general proabbility measures. The approach still works without restricting optimal weights to be in the unit simplex, which would allow for extrapolation beyond the convex hull of the control units, providing a notion of tangential regression. It can also be extended to a continuum of measures, using established consistency results of barycenters (e.g. Le Gouic & Loubes, 2017).", "reference_paragraph": "We have developed a projection method between sets of probability measures supported on R d based on the tangent cone structure of the 2-Wasserstein space. Our method seeks to best approximate some general target measure using some chosen set of control measures. In particular, it provides a global (and in most cases unique) optimal solution. Our application to evaluating the ﬁrst- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010) demonstrates the method’s utility in allowing for a method that is applicable for general probability measures. The method still works without restricting optimal weights to be in the unit simplex, which would allow for extrapolation beyond the convex hull of the control units, providing a notion of tangential regression. It can also be extended to a continuum of measures, using established consistency results of barycenters (e.g. Le Gouic & Loubes, 2017).", "model_A_paragraph": "We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation yielding unique, interpretable weights for regular probability measures, and for general measures, we construct our projection via barycentric projection of optimal transport plans. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator demonstrates the method's efficiency and the necessity for a method applicable to general probability measures. The approach allows for extrapolation beyond the convex hull of control units, providing a notion of tangential regression, and can be extended to a continuum of measures using established consistency results of barycenters.", "model_B_paragraph": "We have developed a projection method between sets of probability measures supported on R d based on the tangential structure of the 2-Wasserstein space. Our method seeks to best approximate some target distribution that is potentially multivariate, using some chosen set of control distributions. We provide an implementation with unique, interpretable weights by constructing a regular tangent space for general probability measures via barycentric projection. Our application to evaluating the first- and second-order effects of Medicaid expansion in Montana via an extension of the synthetic controls estimator (Abadie & Gardeazabal, 2003, Abadie et al., 2010) demonstrates the method’s efficiency and the necessity to have a method that is applicable for general probability measures. The approach still works without restricting optimal weights to be in the unit simplex, which would allow for extrapolation beyond the convex hull of the control units, providing a notion of tangential regression. It can also be extended to a continuum of measures, using established consistency results of barycenters (e.g. Le Gouic & Loubes, 2017).", "labels": ["Concision", "Rewriting_light"], "instruction": "Combine sentences 3 and 4 into a really short one keeping only the main idea. Improve the choice of wording.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "B", "Rewriting_light": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_06"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "id_pairing": 3450, "pararev_annot": "annot_2", "pararev_annotator": "annotator_09", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Design A supportstwo sorts of medication entries: drug or phys- ical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "reference_paragraph": "Design A supports medication (or drug) entries and physical activ- ities. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "model_A_paragraph": "Design A accommodates two categories of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "model_B_paragraph": "The calendar feature of Design A accommodates two types of entries: medication and physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "labels": ["Rewriting_medium"], "instruction": "I want to rewrite the first sentence.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "id_pairing": 3451, "pararev_annot": "annot_2", "pararev_annotator": "annotator_09", "model_A": "coedit-xl", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Design A supportstwo sorts of medication entries: drug or phys- ical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "reference_paragraph": "Design A supports medication (or drug) entries and physical activ- ities. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "model_A_paragraph": "Design A supportstwo sorts of medication entries: drug or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "model_B_paragraph": "Two types of entries are featured in the design of the calendar: medication and physical activity. Drug entries are identified by the name of the medication and a bracketed dosage, with a suffix \"-WF\" indicating that the drug should be taken with food. In contrast, physical activity entries are distinguished by their full-color fill, dashed border, and a label announcing the name of the activity. The remaining calendar entries are denoted by rectangles with various shades of grey.", "labels": ["Rewriting_medium"], "instruction": "I want to rewrite the first sentence.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.11", "id_pairing": 3452, "pararev_annot": "annot_2", "pararev_annotator": "annotator_09", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "Design A supportstwo sorts of medication entries: drug or phys- ical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "reference_paragraph": "Design A supports medication (or drug) entries and physical activ- ities. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "model_A_paragraph": "Design A supports two types of medication entries: medication or physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "model_B_paragraph": "Design A accommodates two types of medication entries: drug and physical activity. Each drug entry in the calendar is labelled with the name of the drug and suffixed with bracketed drug dosage. The suffix -WF indicates that the drug should be administered with food. Physical activity entries have a full-color fill, a dashed border, and a label indicating the name of the activity. All other calendar entries are represented with rectangles filled with different shades of grey.", "labels": ["Rewriting_medium"], "instruction": "I want to rewrite the first sentence.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_medium": "None", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "id_pairing": 3990, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch  changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "reference_paragraph": "Changing the notch to an area where the cursor cannot enter can be considered as an effective approach as the avoid-strategy was found to be desirable in Experiment 2. Experiment 3 was almost the same experiment as Experiment 2; however, the notch was changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in Experiment 2.", "model_A_paragraph": "Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "model_B_paragraph": "Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "labels": ["Rewriting_medium"], "instruction": "Reorder the first sentence.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Rewriting_medium": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "id_pairing": 3991, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch  changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "reference_paragraph": "Changing the notch to an area where the cursor cannot enter can be considered as an effective approach as the avoid-strategy was found to be desirable in Experiment 2. Experiment 3 was almost the same experiment as Experiment 2; however, the notch was changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in Experiment 2.", "model_A_paragraph": "Changing the notch to an area where the cursor cannot enter can be considered because the avoid-strategy was shown to be desirable in experiment 2. Experiment 3 was almost the same experiment as experiment 2, however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "model_B_paragraph": "Changing the notch to an area where the cursor cannot enter can be considered because avoid-strategy was shown to be desirable in experiment 2. Experiment 3 was almost the same experiment as experiment 2, however, the notch  changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "labels": ["Rewriting_medium"], "instruction": "Reorder the first sentence.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.22", "id_pairing": 3992, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Because avoid-strategy was shown to be desirable in experiment 2, changing the notch to an area where the cursor cannot enter can be considered. Experiment 3 was almost the same experiment as experiment 2, however, the notch  changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "reference_paragraph": "Changing the notch to an area where the cursor cannot enter can be considered as an effective approach as the avoid-strategy was found to be desirable in Experiment 2. Experiment 3 was almost the same experiment as Experiment 2; however, the notch was changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in Experiment 2.", "model_A_paragraph": "Changing the notch to an area where the cursor cannot enter can be considered because the avoid-strategy was shown to be desirable in experiment 2. Experiment 3 was almost the same experiment as experiment 2; however, the notch changed to an area where the cursor cannot enter. The apparatuses, participants, task, and measurements were the same as in experiment 2.", "model_B_paragraph": "In experiment 3, similar to experiment 2, the apparatuses, participants, task, and measurements were the same. However, in this experiment, the notch was changed to an area where the cursor cannot enter, following the desirable avoid-strategy shown in experiment 2.", "labels": ["Rewriting_medium"], "instruction": "Reorder the first sentence.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "id_pairing": 4340, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "coedit-xl", "model_B": "gpt-4o-mini", "original_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that  for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights  notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difﬁcult in a fully-connected GCN.", "reference_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) to act over AGILE’s action graph. We observe that GCN achieves optimal performance for the grid world and RecSys tasks. GCN can learn simple action relations even though the edge weights are not learned. However, it suffers in CREATE and RecSim-pairing (Figure 16), where the action relations are diverse and plenty. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difﬁcult in a fully-connected GCN.", "model_A_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) in the action graph of AGILE. We observe that for thesimple grid world and RecSim tasks, GCN achieves optimal performance.", "model_B_paragraph": "We validate the use of the graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. For the simple grid world and RecSim tasks, GCN achieves optimal performance as it acts like a summarizer despite unlearned edge weights. However, it struggles in CREATE and RecSim-pairing (Figure 16) where a large action space demands diverse action relations. We believe that the attention mechanism in GAT promotes graph sparsity, facilitating RL training, which is challenging in a fully-connected GCN.", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make this paragraph a bit more concise.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "id_pairing": 4341, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that  for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights  notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difﬁcult in a fully-connected GCN.", "reference_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) to act over AGILE’s action graph. We observe that GCN achieves optimal performance for the grid world and RecSys tasks. GCN can learn simple action relations even though the edge weights are not learned. However, it suffers in CREATE and RecSim-pairing (Figure 16), where the action relations are diverse and plenty. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difﬁcult in a fully-connected GCN.", "model_A_paragraph": "We validate the choice of using graph attention network as the relational architecture. Figure 7 compares GAT against GCN in the action graph of AGILE, showing that GCN achieves optimal performance in simple grid world and RecSim tasks, acting as a summarizer despite unlearned edge weights. However, GCN suffers in CREATE and RecSim-pairing tasks with large action spaces and diverse action relations, whereas GAT's attention mechanism makes the graph sparse, easing RL training, unlike fully-connected GCN.", "model_B_paragraph": "We validate the choice of graph attention network (GAT) as the relational architecture. Figure 7 compares GAT with graph convolutional network (GCN) (Kipf & Welling, 2016) in the AGILE action graph. While GCN achieves optimal performance in simple tasks due to its summarization capabilities, GAT outperforms it in tasks with large action spaces, such as CREATE and RecSim-pairing, where diverse action relations are required. Additionally, we believe that GAT's attention mechanism makes the graph sparse, facilitating RL training, which is challenging in fully-connected GCNs.", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make this paragraph a bit more concise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Concision": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.17", "id_pairing": 4342, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o", "original_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) in the action graph of AGILE. We observe that  for thesimple grid world and RecSim tasks, GCN achieves optimal performance. This is because GCN can still act like a summarizer, despite the edge weights  notbeing learned. However, it suffers in CREATE and RecSim-pairing (Figure 16) where the action space is large and requires diverse action relations. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difﬁcult in a fully-connected GCN.", "reference_paragraph": "We validate the choice of using graph attention network as the relational architecture. In Figure 7, we compare GAT against a graph convolutional network (GCN) (Kipf & Welling, 2016) to act over AGILE’s action graph. We observe that GCN achieves optimal performance for the grid world and RecSys tasks. GCN can learn simple action relations even though the edge weights are not learned. However, it suffers in CREATE and RecSim-pairing (Figure 16), where the action relations are diverse and plenty. Moreover, we believe that the attention in GAT makes the graph sparse to ease RL training, which in contrast, is difﬁcult in a fully-connected GCN.", "model_A_paragraph": "We validate the use of graph attention networks (GAT) as the relational architecture over graph convolutional networks (GCN) in Figure 7 for AGILE's action graphs. While GCN outperforms GAT in simple grid world and RecSim tasks due to its ability to summarize relations, GAT excels in larger action spaces like CREATE and RecSim-pairing due to its attention mechanism that sparsifies the graph. This eases RL training in GAT, whereas fully-connected GCNs face difficulty in this regard.", "model_B_paragraph": "We validate using a graph attention network (GAT) as the relational architecture. Figure 7 compares GAT with a graph convolutional network (GCN) (Kipf & Welling, 2016) in AGILE's action graph. GCN achieves optimal performance in simple grid world and RecSim tasks because it acts as a summarizer, despite non-learned edge weights. However, it underperforms in CREATE and RecSim-pairing (Figure 16) due to a large action space requiring diverse action relations. We believe GAT's attention mechanism sparsifies the graph to facilitate RL training, which is challenging in a fully-connected GCN.", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make this paragraph a bit more concise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Concision": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "id_pairing": 3700, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "coedit-xl", "original_paragraph": "It is necessary to emphasize our difference with emerging  causal inference approaches based on optimal transport. Dunipace (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.", "reference_paragraph": "It is necessary to distinguish ourselves from emerging OT-based causal inference approaches. Dunipace (2021) augments the IPS method with a propensity score estimator based on OT; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push-forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) has a similar setup to to us, while it focuses on the decomposition of latent variables and is identical to Shalit et al. (2017) in terms of alignment technology. Our work is a new take on OT under the CFR framework, alleviating the MSE and UCE issues that have been long neglected by the causal inference community until this year.", "model_A_paragraph": "We differ from emerging causal inference approaches based on optimal transport. Dunipace (2021) improved the IPS method using optimal transport, but was limited by high variance. Torous et al. (2021) used the push forward operator to enhance change-in-change models, but these are designed for multi-phase data, which is not available in our case. Li et al. (2022) shares similar settings, focusing on variable decomposition in latent space, similar to Uri et al. (2017) in terms of alignment technology. Our contribution is investigating the role and flexibility of optimal transport to augment CFR, mitigating MSE and UCE issues that have been long overlooked.", "model_B_paragraph": "It is necessary to emphasize our difference with emerging causal inference approaches based on optimal transport.", "labels": ["Rewriting_light", "Concision"], "instruction": "Make this paragraph more simple to read and concise phrases that are too long when possible.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "id_pairing": 3701, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "It is necessary to emphasize our difference with emerging  causal inference approaches based on optimal transport. Dunipace (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.", "reference_paragraph": "It is necessary to distinguish ourselves from emerging OT-based causal inference approaches. Dunipace (2021) augments the IPS method with a propensity score estimator based on OT; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push-forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) has a similar setup to to us, while it focuses on the decomposition of latent variables and is identical to Shalit et al. (2017) in terms of alignment technology. Our work is a new take on OT under the CFR framework, alleviating the MSE and UCE issues that have been long neglected by the causal inference community until this year.", "model_A_paragraph": "We must highlight how we differ from new causal inference methods that use optimal transport. Dunipace (2021) enhances the IPS method with a propensity score estimator based on optimal transport, but it faces a high variance issue. Torous et al. (2021) apply the push forward operator to improve change-in-change models, but their approach is intended for multi-phase data, which is not applicable in our case. Li et al. (2022) have a similar context but focus on variable decomposition in latent space, aligning with Uri et al. (2017) in their alignment technology. Our contribution is in exploring how optimal transport can enhance CFR, addressing MSE and UCE issues that have long been overlooked in the literature, even as recent as this year.", "model_B_paragraph": "We distinguish our approach from emerging causal inference methods based on optimal transport. For instance, Dunipace (2021) uses optimal transport to improve the IPS method, but it still suffers from high variance. Torous et al. (2021) apply optimal transport to change-in-change models, but their approach requires multi-phase data, which is not available in our case. Li et al. (2022) share similar settings, but focus on variable decomposition in latent space, similar to Uri et al. (2017). Our contribution is to explore the role of optimal transport in augmenting CFR, addressing the long-standing MSE and UCE issues that have been overlooked in recent literature.", "labels": ["Rewriting_light", "Concision"], "instruction": "Make this paragraph more simple to read and concise phrases that are too long when possible.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.20", "id_pairing": 3702, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o", "original_paragraph": "It is necessary to emphasize our difference with emerging  causal inference approaches based on optimal transport. Dunipace (2021) augments the IPS method via a propensity score estimator based on optimal transport; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) shares similar settings to us, while they focuses on variable decomposition in latent space and is identical to Uri et al. (2017) in terms of alignment technology. Our contribution lies in investigating the role and flexibility of optimal transport to augment CFR, mitigating the MSE and UCE issues that have been long circumvented in the literature as recent as this year.", "reference_paragraph": "It is necessary to distinguish ourselves from emerging OT-based causal inference approaches. Dunipace (2021) augments the IPS method with a propensity score estimator based on OT; however, it is limited by the aforementioned high variance issue. Torous et al. (2021) uses the push-forward operator to improve change-in-change models; however, they are designed for multi-phase data which is not available in our case. Li et al. (2022) has a similar setup to to us, while it focuses on the decomposition of latent variables and is identical to Shalit et al. (2017) in terms of alignment technology. Our work is a new take on OT under the CFR framework, alleviating the MSE and UCE issues that have been long neglected by the causal inference community until this year.", "model_A_paragraph": "Our approach diverges from recent optimal transport-based causal inference methods. Dunipace (2021) enhances the IPS method with an optimal transport propensity score estimator but faces high variance. Torous et al. (2021) employ the push forward operator for change-in-change models, designed for multi-phase data unavailable in our study. Li et al. (2022) share our setting but focus on variable decomposition in latent space, identical to Uri et al. (2017) in alignment technology. We explore the utility of optimal transport to enhance Combinatorial Causal Forests, addressing long-standing MSE and UCE issues in the literature.", "model_B_paragraph": "It is essential to highlight our differences from emerging causal inference approaches using optimal transport. Dunipace (2021) enhances the IPS method with a propensity score estimator based on optimal transport, but it suffers from high variance issues. Torous et al. (2021) use the push-forward operator to improve change-in-change models, designed for multi-phase data, which is not applicable to our data. Li et al. (2022) shares a similar setting with us, focusing on variable decomposition in latent space, similar to Uri et al. (2017) in alignment technology. Our contribution explores the role and flexibility of optimal transport to enhance CFR, addressing the MSE and UCE issues commonly overlooked in recent literature.", "labels": ["Rewriting_light", "Concision"], "instruction": "Make this paragraph more simple to read and concise phrases that are too long when possible.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_light": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "id_pairing": 2520, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "MIMO’s experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code will be open-sourced.", "reference_paragraph": "We described and analyzed MIMO. In this section, we compare MIMO on benchmarks building on Uncertainty Baselines. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code is open-sourced.", "model_A_paragraph": "In this section, we present the experiments conducted using MIMO, which are built upon the Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code will be open-sourced.", "model_B_paragraph": "In this section, we present the results of MIMO's experiments, which are based on the Uncertainty Baselines framework. This structure enables us to evaluate and compare MIMO's performance against highly optimized implementations of baseline methods (further details on these baselines can be found in the framework). We focus on three model-dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. Upon completion of our study, we intend to release MIMO's code as open-source.", "labels": ["Rewriting_medium"], "instruction": "Rewrite the first sentence to also explain the structure of the section.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "id_pairing": 2521, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "MIMO’s experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code will be open-sourced.", "reference_paragraph": "We described and analyzed MIMO. In this section, we compare MIMO on benchmarks building on Uncertainty Baselines. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code is open-sourced.", "model_A_paragraph": "This section begins by explaining how MIMO’s experiments build on the Uncertainty Baselines framework, followed by benchmarking the performance and comparing against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code will be open-sourced.", "model_B_paragraph": "This section discusses MIMO's experiments, which build on the Uncertainty Baselines framework and are structured around three specific model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). MIMO’s code will be open-sourced.", "labels": ["Rewriting_medium"], "instruction": "Rewrite the first sentence to also explain the structure of the section.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "9T9ueD0PUu.7Pcj7508I2.01", "id_pairing": 2522, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "MIMO’s experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code will be open-sourced.", "reference_paragraph": "We described and analyzed MIMO. In this section, we compare MIMO on benchmarks building on Uncertainty Baselines. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code is open-sourced.", "model_A_paragraph": "MIMO's experiments build onthe Uncertainty Baselines framework. This framework allows us to benchmark the performance and to compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO's code will be open-sourced.", "model_B_paragraph": "This section presents the experimental design of MIMO, which is built on the Uncertainty Baselines framework, allowing us to benchmark the performance and compare against high-quality, well-optimized implementations of baseline methods (see framework for further baselines than ones highlighted here). We looked at three model/dataset combinations: ResNet28-10/CIFAR10, ResNet28-10/CIFAR100, and ResNet50/ImageNet. MIMO’s code will be open-sourced.", "labels": ["Rewriting_medium"], "instruction": "Rewrite the first sentence to also explain the structure of the section.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "id_pairing": 1090, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "reference_paragraph": "The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. We introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "model_A_paragraph": "The novelty of our work lies in using a discrete representation for structured search on two levels. We reinforce the necessity of the discrete latent space by introducing two ablative baselines that replace the VQ-VAE with a generic autoencoder or a VAE.", "model_B_paragraph": "Our work's central novelty lies in using a discrete representation for structured search on two levels. To validate the necessity of this approach, we introduce two ablative baselines, replacing the VQ-VAE with a generic autoencoder or VAE.", "labels": ["Concision"], "instruction": "Make this paragraph shorter.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "id_pairing": 1091, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "coedit-xl", "original_paragraph": "The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "reference_paragraph": "The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. We introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "model_A_paragraph": "The central novelty of our work is recognizing that learning a discrete representation enables structured search on two levels. We introduce two ablative baselines, replacing the VQ-VAE with either a generic autoencoder or a VAE to demonstrate the necessity of the discrete latent space.", "model_B_paragraph": "The central novelty of our work is that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "labels": ["Concision"], "instruction": "Make this paragraph shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "mS4xvgSiEH.i-a3xp3usm.00", "id_pairing": 1092, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. To ensure that the discrete latent space is necessary, we introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "reference_paragraph": "The central novelty of our work is in realizing that by learning a discrete representation, we can perform structured search on two levels. We introduce two ablative baselines, which replace the VQ-VAE with either a generic autoencoder or a VAE.", "model_A_paragraph": "Our work's novelty lies in utilizing a discrete representation to support two-level structured search. We verify the necessity of the discrete latent space through two ablative baselines: replacing VQ-VAE with a generic autoencoder or VAE.", "model_B_paragraph": "Our work's novelty lies in learning a discrete representation, enabling structured search on two levels. We introduce two ablative baselines, replacing the VQ-VAE with a generic autoencoder or a VAE, to demonstrate the necessity of the discrete latent space.", "labels": ["Concision"], "instruction": "Make this paragraph shorter.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "id_pairing": 2330, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o-mini", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with β = \n (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95 . Full-batch gradient descent with momentum (GD+M) performed for various β with a fixed step-size h − 0 . 1 and the best test-accuracy is noted (in Figure 3) to be 96 . Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all β ’s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h , called “the edge of stability”. And for (GD+M), the sharpness can reach up to 2(1+ β ) h , hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the  implicit regularization  for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.", "reference_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with β = \n (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95 . Full-batch gradient descent with momentum (GD+M) performed for various β with a fixed step-size h = 0 . 1 and the best test-accuracy is noted (in Figure 3) to be 96 . Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all β ’s). This observation failed to be explained by the known theory of edge of stability 3 but can be well-explained by our implicit regularization theory for (GD+M) as adding momentum increases the strength of the IGR.", "model_A_paragraph": "The MNIST dataset was used with 1000 training images, and all external regularization schemes, except for learning rate decay and batch normalization, were turned off. We conducted several experiments: 1) Full-batch gradient descent (GD) with various learning rates h achieved a best test accuracy of 95, as shown in Figure 2. 2) Full-batch gradient descent with momentum (GD+M), using a fixed step size of h = 0.1 and various β values, reached a best test accuracy of 96, illustrated in Figure 3. Our observation indicates that the best performance of GD (across all learning rates) is inferior to that of GD+M (across all β values). Cohen et al. (2021) demonstrated that gradient descent tends to increase sharpness until it reaches 2h, termed “the edge of stability.” In contrast, GD+M can achieve sharpness levels up to 2(1+β)h, allowing it to enter a sharper region before instability. Although a greater allowable sharpness for GD+M compared to GD might suggest higher test accuracy for GD, our experiments contradict this expectation. We posit that the implicit regularization for GD+M contributes significantly, as we believe that implicit gradient regularization for momentum outweighs the sharpness effect in achieving improved test accuracy.", "model_B_paragraph": "The MNIST dataset included 1000 training images with no external regularization schemes except learning rate decay and batch normalization. We conducted the following experiments: 1) Full-batch gradient descent (GD) with various learning rates β, and the highest test accuracy of 95 was achieved (as shown in Figure 2). 2) Full-batch gradient descent with momentum (GD+M) using a fixed step-size h-0.1 for various β, resulting in the highest test-accuracy of 96 (presented in Figure 3). Our findings indicate that GD's best performance (across all learning rates) underperformed compared to GD+M's best performance (across all β). This contrast is likely due to the impact of implicit regularization (IGR) in GD+M. Cohen et al. (2021) noted that GD's tendency is to increase sharpness up to h, labeled \"the edge of stability.\" In contrast, GD+M allows for sharpness up to (1+β)h, potentially entering a sharper region before instability. However, the experiment does not support the assumption that GD+M's greater allowable sharpness implies a higher test accuracy.", "labels": ["Content_deletion", "Concision"], "instruction": "Summarize heavily the results and explanations obtained. Fix any typos.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "id_pairing": 2331, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with β = \n (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95 . Full-batch gradient descent with momentum (GD+M) performed for various β with a fixed step-size h − 0 . 1 and the best test-accuracy is noted (in Figure 3) to be 96 . Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all β ’s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h , called “the edge of stability”. And for (GD+M), the sharpness can reach up to 2(1+ β ) h , hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the  implicit regularization  for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.", "reference_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with β = \n (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95 . Full-batch gradient descent with momentum (GD+M) performed for various β with a fixed step-size h = 0 . 1 and the best test-accuracy is noted (in Figure 3) to be 96 . Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all β ’s). This observation failed to be explained by the known theory of edge of stability 3 but can be well-explained by our implicit regularization theory for (GD+M) as adding momentum increases the strength of the IGR.", "model_A_paragraph": "The MNIST dataset with 1000 training images was used, with most regularization schemes turned off except for learning rate decay and batch normalization. Experiments included full-batch gradient descent (GD) varying the learning rate, achieving a best test accuracy of 95%, and gradient descent with momentum (GD+M), which was tested with various momentum values and a fixed step size, achieving a best test accuracy of 96%. GD tends to increase sharpness up to the stability threshold, whereas GD+M allows greater sharpness, theoretically enabling better accuracy. However, the observed results showed GD+M achieving higher accuracy than GD. This may be attributed to the implicit regularization effect of momentum, which seems to exceed the sharpness effect in improving test accuracy.", "model_B_paragraph": "The MNIST dataset with 1000 training images was used. All external regularization schemes except learning rate decay and batch normalization were disabled. We conducted the following experiments: full-batch gradient descent (GD) with varying learning rates, achieving a best test accuracy of 95% (Figure 2), and full-batch gradient descent with momentum (GD+M) with a fixed step-size, achieving a best test accuracy of 96% (Figure 3). Notably, the best performance of GD was outperformed by that of GD+M. This contrasts with the expectation that GD's increased sharpness would lead to better test accuracy, as shown by Cohen et al. (2021). Instead, we attribute the better performance of GD+M to its implicit regularization, which outweighs the sharpness effect.", "labels": ["Content_deletion", "Concision"], "instruction": "Summarize heavily the results and explanations obtained. Fix any typos.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Concision": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "nElUizYNh.CZNfAQwVJ.00", "id_pairing": 2332, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with β = \n (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95 . Full-batch gradient descent with momentum (GD+M) performed for various β with a fixed step-size h − 0 . 1 and the best test-accuracy is noted (in Figure 3) to be 96 . Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all β ’s). (Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h , called “the edge of stability”. And for (GD+M), the sharpness can reach up to 2(1+ β ) h , hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+M) than that of (GD) may suggest a higher test accuracy for (GD), this is not what we observe from the above experiment. We think the  implicit regularization  for (GD+M) plays a part in it. We believe IGR for momentum outweighs the sharpness effect in achieving better test accuracy.", "reference_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with β = \n (i.e., GD) for various learning rate h and the best test accuracy is noted (in Figure 2) to be 95 . Full-batch gradient descent with momentum (GD+M) performed for various β with a fixed step-size h = 0 . 1 and the best test-accuracy is noted (in Figure 3) to be 96 . Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all β ’s). This observation failed to be explained by the known theory of edge of stability 3 but can be well-explained by our implicit regularization theory for (GD+M) as adding momentum increases the strength of the IGR.", "model_A_paragraph": "MNIST dataset with 1000 training images. All external regularization schemes except learning rate decay and batch normalization have been turned off. We perform the following experiments : 1 ) Full-batch gradient descent with  = (i.e., GD) for various learning rates h and the best test accuracy is noted (in Figure 2) to be 95. GD+M performed for various  with a fixed step-size h  0. 1 and the best test accuracy is noted (in Figure 3) to be 96. Our observation is that the best performance of GD (across all learning rates) is worse than the best performance of (GD+M) (across all  ’s). Cohen et al., 2021) showed that gradient descent (GD) has an overwhelming tendency to increase the sharpness 2 till it reaches 2 h, called “the edge of stability”. And for (GD+M), the sharpness can reach up to 2(1+  ) h, hence allowing it to enter a sharper region before becoming unstable. As greater allowable sharpness for (GD+", "model_B_paragraph": "We conducted experiments on the MNIST dataset with 1000 training images, disabling all external regularization schemes except learning rate decay and batch normalization. Our results show that full-batch gradient descent with momentum (GD+M) outperforms full-batch gradient descent (GD), achieving a best test accuracy of 96% compared to 95%. This contradicts the expectation that GD+M's ability to reach sharper regions would lead to better test accuracy. We attribute this to the implicit regularization effect of momentum, which outweighs the sharpness effect.", "labels": ["Content_deletion", "Concision"], "instruction": "Summarize heavily the results and explanations obtained. Fix any typos.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_07"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "id_pairing": 1310, "pararev_annot": "annot_2", "pararev_annotator": "annotator_02", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o", "original_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. Conditional utilization rate was however can be measured once training was done, making it difﬁcult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed , that captures relative learning speed between modalities during training.", "reference_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rates are measured after training is done, making it expensive to use them in real-time during training. We instead derive a proxy metric, called conditional learning speed , that captures relative learning speed between modalities during training.", "model_A_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, since conditional utilization rate can only be measured after training is complete, it is not suitable for real-time monitoring during the training process. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.", "model_B_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, measuring the conditional utilization rate is only possible after the training is completed, which makes it challenging to use in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.", "labels": ["Rewriting_light"], "instruction": "Revise the wording of the middle sentence in this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "id_pairing": 1311, "pararev_annot": "annot_2", "pararev_annotator": "annotator_02", "model_A": "coedit-xl", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. Conditional utilization rate was however can be measured once training was done, making it difﬁcult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed , that captures relative learning speed between modalities during training.", "reference_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rates are measured after training is done, making it expensive to use them in real-time during training. We instead derive a proxy metric, called conditional learning speed , that captures relative learning speed between modalities during training.", "model_A_paragraph": "As demonstrated in 3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rate was however can be measured once training was done, making it difficult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.", "model_B_paragraph": "As shown in §3.2, an imbalance in conditional utilization rates indicates that the model favors the connection between the target and one input modality over others, disregarding crossmodal information. Although conditional utilization rates can be measured after training, their calculation proves challenging for real-time use during training. Consequently, we introduce a proxy metric, termed conditional learning speed, which quantifies the disparity in learning speeds between modalities during training.", "labels": ["Rewriting_light"], "instruction": "Revise the wording of the middle sentence in this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "7_CwM-IzWd.zcm6f5HDI.08", "id_pairing": 1312, "pararev_annot": "annot_2", "pararev_annotator": "annotator_02", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "gpt-4o-mini", "original_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. Conditional utilization rate was however can be measured once training was done, making it difﬁcult to use it in real-time during training. We instead derive a proxy metric, called conditional learning speed , that captures relative learning speed between modalities during training.", "reference_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rates are measured after training is done, making it expensive to use them in real-time during training. We instead derive a proxy metric, called conditional learning speed , that captures relative learning speed between modalities during training.", "model_A_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. Conditional utilization rate can be measured only after training is complete, which makes it impractical for real-time monitoring during training. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.", "model_B_paragraph": "As demonstrated in §3.2, the imbalance in conditional utilization rates is a sign of the model exploiting the connection between the target and only one of the input modalities, ignoring crossmodal information. However, conditional utilization rates can only be measured after training, which complicates their use in real-time during the training process. We instead derive a proxy metric, called conditional learning speed, that captures relative learning speed between modalities during training.", "labels": ["Rewriting_light"], "instruction": "Revise the wording of the middle sentence in this paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "id_pairing": 2490, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "coedit-xl", "original_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no “simple” baselines. For example, a very simple  baseline  would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "reference_paragraph": "The baselines used to assess the performance of AutoML tools are often other AutoML tools or random search. A simple but perhaps more sensible baseline than random search would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is (Thornton et al., 2013), using the Exhaustive-Default (“Ex-def”) baseline which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_A_paragraph": "The baselines used to assess AutoML tools are typically limited to other AutoML tools, neglecting \"simple\" alternatives. A straightforward approach, for instance, would be to mimic the steps a human data scientist would take, which should be considered as a baseline. Without such baselines, we only learn how AutoML tools compare to each other, not how they improve upon ad-hoc techniques. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_B_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other.", "labels": ["Concision", "Rewriting_light"], "instruction": "Make the beginning of the paragraph shorter.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "id_pairing": 2491, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no “simple” baselines. For example, a very simple  baseline  would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "reference_paragraph": "The baselines used to assess the performance of AutoML tools are often other AutoML tools or random search. A simple but perhaps more sensible baseline than random search would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is (Thornton et al., 2013), using the Exhaustive-Default (“Ex-def”) baseline which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_A_paragraph": "Baselines used to assess the performance of AutoML tools typically involve only other AutoML tools rather than “simple” baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_B_paragraph": "The use of other AutoML tools as baselines to assess performance is common. For example, Thornton et al. (2013) proposed the Exhaustive-Default (\"Ex-def\") baseline, which selects the best parametrized model from cross-validation as a simple baseline. A more rudimentary baseline could be an approach mimicking a human data scientist's steps. Omitting such baselines limits understanding of AutoML tools' improvements over ad-hoc techniques, merely showing their relative performance. We are not aware of any other work concerning these baselines except Thornton et al.'s discussion of grid search, which isn't feasible in practice.", "labels": ["Concision", "Rewriting_light"], "instruction": "Make the beginning of the paragraph shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "id_pairing": 2492, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no “simple” baselines. For example, a very simple  baseline  would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "reference_paragraph": "The baselines used to assess the performance of AutoML tools are often other AutoML tools or random search. A simple but perhaps more sensible baseline than random search would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is (Thornton et al., 2013), using the Exhaustive-Default (“Ex-def”) baseline which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_A_paragraph": "Typically, the baselines used to assess the performance of AutoML tools are other AutoML tools, neglecting “simple” baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_B_paragraph": "For example, a simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "labels": ["Concision", "Rewriting_light"], "instruction": "Make the beginning of the paragraph shorter.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "No", "acceptable": "None", "correctness_A": false, "correctness_B": false, "preference": "None", "Concision": "None", "Rewriting_light": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "id_pairing": 4850, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o-mini", "original_paragraph": "This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.", "reference_paragraph": "This issue is attributed to the mass-preservation constraint in (5), which requires that all units in both groups match each other, regardless of the actual situation. Mini-batch outliers, for instance, would be compelled to be transported according to Figure 2, which impedes the transport of normal units and the computation of the actual group discrepancy. A small batch size would exacerbate this defect.", "model_A_paragraph": "The primary cause of this issue is the mass preservation constraint. This constraint necessitates that units identified as outliers at the mini-batch level are transported, as shown in Figure 1. This, in turn, impairs the transportation of regular units and increases the vulnerability of the group discrepancy to sampling effects. This issue becomes more pronounced with a small batch size.", "model_B_paragraph": "This issue primarily arises from the mass preservation constraint. Specifically, units that behave as outliers at the mini-batch level are compelled to be transported according to this marginal constraint, as shown in Figure 1. This situation obstructs the transport of typical units and makes the group discrepancy susceptible to the sampling effect. Moreover, this problem is worsened by a small batch size.", "labels": ["Rewriting_medium"], "instruction": "Rewrite this paragraph to make it more easily readable.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "id_pairing": 4851, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.", "reference_paragraph": "This issue is attributed to the mass-preservation constraint in (5), which requires that all units in both groups match each other, regardless of the actual situation. Mini-batch outliers, for instance, would be compelled to be transported according to Figure 2, which impedes the transport of normal units and the computation of the actual group discrepancy. A small batch size would exacerbate this defect.", "model_A_paragraph": "This issue arises primarily from the mass preservation constraint. Specifically, units that act as outliers at the mini-batch level are forced to be transported by this marginal constraint, as illustrated in Figure 1. As a result, the transport of normal units is hindered, making the group discrepancy susceptible to the sampling effect. Furthermore, this issue is exacerbated by the small batch size.", "model_B_paragraph": "The main issue arises from the mass preservation constraint. As illustrated in Figure 1, units that act as outliers at the mini-batch level are compelled to be transported by this marginal constraint, which hinders the transport of normal units and makes the group discrepancy vulnerable to the sampling effect. This problem is further exacerbated by the small batch size.", "labels": ["Rewriting_medium"], "instruction": "Rewrite this paragraph to make it more easily readable.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "Both", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "OV5v_wBMHk.bw4cqlpLh.10", "id_pairing": 4852, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "gpt-4o", "original_paragraph": "This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.", "reference_paragraph": "This issue is attributed to the mass-preservation constraint in (5), which requires that all units in both groups match each other, regardless of the actual situation. Mini-batch outliers, for instance, would be compelled to be transported according to Figure 2, which impedes the transport of normal units and the computation of the actual group discrepancy. A small batch size would exacerbate this defect.", "model_A_paragraph": "This issue stems mainly from the mass preservation constraint. Specifically, units acting as outliers at a mini-batch level would be forced to be transported by this marginal constraint, as depicted in Figure 1. It hinders the transport of normal units andmakes the group discrepancy vulnerable to the sampling effect. Such issue would be exacerbated by the small batch size.", "model_B_paragraph": "This issue mainly arises from the mass preservation constraint. Specifically, units that are outliers at the mini-batch level are forcibly transported due to this marginal constraint, as shown in Figure 1. This process obstructs the transportation of normal units and makes the group discrepancy susceptible to the sampling effect. Such an issue is worsened by the small batch size.", "labels": ["Rewriting_medium"], "instruction": "Rewrite this paragraph to make it more easily readable.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "None", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "id_pairing": 3810, "pararev_annot": "annot_2", "pararev_annotator": "annotator_09", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "gpt-4o", "original_paragraph": "When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa. The calendar should also have support for indication that a given entry is optional. Suchsupport targets entries such as prescription medication that should be taken as needed and non-prescription medication that is bought over the counter. These design decisions are influenced by everyday activities that users are familiar with.", "reference_paragraph": "When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that medication entries that have been sched- uled too close together should be taken apart and vice-versa. The calendar should also have support for indication that a given entry is optional. Such entries would be used for medications that should be administered “as needed” and non-prescription medications that are sold “over the counter”. These design decisions are influenced by everyday activities that users are familiar with.", "model_A_paragraph": "When dealing with conflicts, arrows are effective in communicating the suggested conflict resolution action. End-of-line arrows can be used to indicate that medication entries scheduled too close together should be separated or combined. The calendar should also have support for indicating that a given entry is optional, such as prescription medication to be taken as needed and over-the-counter non-prescription medication. These design decisions are influenced by everyday activities that users are familiar with.", "model_B_paragraph": "When managing conflicts, arrows effectively convey the recommended actions for conflict resolution. End-of-line arrows can indicate that medication entries scheduled too closely should be spaced apart and vice-versa. The calendar should also be able to denote optional entries. This feature addresses entries like prescription medications taken as needed and non-prescription medications purchased over the counter. These design choices are shaped by users' common daily activities.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Reword my sentence about entries.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "A", "Rewriting_medium": "B", "Rewriting_light": "B", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "id_pairing": 3811, "pararev_annot": "annot_2", "pararev_annotator": "annotator_09", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o-mini", "original_paragraph": "When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa. The calendar should also have support for indication that a given entry is optional. Suchsupport targets entries such as prescription medication that should be taken as needed and non-prescription medication that is bought over the counter. These design decisions are influenced by everyday activities that users are familiar with.", "reference_paragraph": "When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that medication entries that have been sched- uled too close together should be taken apart and vice-versa. The calendar should also have support for indication that a given entry is optional. Such entries would be used for medications that should be administered “as needed” and non-prescription medications that are sold “over the counter”. These design decisions are influenced by everyday activities that users are familiar with.", "model_A_paragraph": "In managing conflicts, arrows prove useful in conveying the proposed course of action for resolution. Arrows at the end of lines can signify that medication entries scheduled excessively close to each other should be separated, and the opposite applies as well. The calendar must also accommodate an indicator for optional entries. This feature particularly caters to medications such as prescription and over-the-counter drugs that can be taken on an as-needed basis. The aforementioned design elements are driven by everyday user experiences.", "model_B_paragraph": "When dealing with conflicts, arrows are effective in communicating the suggested conflict resolution action. End-of-line arrows can be employed to signify that medication entries scheduled too closely together should be separated and vice versa. The calendar should also support indicating that a specific entry is optional. Such support pertains to entries like prescription medications that should be taken as needed and non-prescription medications that are purchased over the counter. These design decisions are influenced by everyday activities that users are familiar with.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Reword my sentence about entries.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.16", "id_pairing": 3812, "pararev_annot": "annot_2", "pararev_annotator": "annotator_09", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "coedit-xl", "original_paragraph": "When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be taken apart and vice-versa. The calendar should also have support for indication that a given entry is optional. Suchsupport targets entries such as prescription medication that should be taken as needed and non-prescription medication that is bought over the counter. These design decisions are influenced by everyday activities that users are familiar with.", "reference_paragraph": "When dealing with conflicts, arrows are effective in communi- cating the suggested conflict resolution action. End-of-line arrows can be used to indicate that medication entries that have been sched- uled too close together should be taken apart and vice-versa. The calendar should also have support for indication that a given entry is optional. Such entries would be used for medications that should be administered “as needed” and non-prescription medications that are sold “over the counter”. These design decisions are influenced by everyday activities that users are familiar with.", "model_A_paragraph": "When resolving conflicts, arrows are useful in conveying suggested conflict resolution actions. End-of-line arrows can be employed to indicate that medication entries that have been scheduled too close together should be separated, or vice versa. The calendar should also accommodate indication of optional entries, such as prescription medication that can be taken as needed and non-prescription medication that is purchased over-the-counter. These design decisions are informed by everyday activities that users are familiar with.", "model_B_paragraph": "Arrows are effective in communicating the suggested conflict resolution action. End-of-line arrows can be used to indicate that the medication entries which have been scheduled too close together should be separated, and vice versa.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Reword my sentence about entries.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "id_pairing": 2430, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each  single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i ( i = 1 . . . n ). The other MLP for amino acid pairs mainly encodes the distance and  relative position between two amino acids and we denote a pair embedding vector as z ij ( i, j = 1 . . . n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings{ e i} and pair embeddings{ z ij} into hidden representations{ h i } . The hidden representation h i is aimed at capturing the informa- tion of both the i -th amino acid itself and its structural environments. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density w.r.t. χ i .", "reference_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each individual single residue and each pair of residues respectively. The MLP for single residues encodes the residue type, backbone dihedral angles, and local atom coordinates into a vector e i ( i = 1 . . . n ). The other MLP for residue pairs encodes the distance and the relative position between two residues. We denote a pair embedding vector as z ij ( i, j = 1 . . . n ). To transform the single embeddings e i and pair embeddings z ij into hidden representations h i , we use a self-attention-based network that is invariant to rotation and translation (Jumper et al., 2021). The hidden representation h i aims to capture both the information of the i -th residue itself and its structural environment. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density with respect to χ i .", "model_A_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single residue and each pair of residues respectively. The MLP for single residues encodes the residue type, backbone dihedral angles, and local atom coordinates of each residue into a vector e i ( i = 1 . . . n ). The other MLP for residue pairs mainly encodes the distance and relative position between two residues and we denote a pair embedding vector as z ij ( i, j = 1 . . . n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings { e i} and pair embeddings { z ij} into hidden representations { h i }. The hidden representation h i is aimed at capturing the information of both the i-th residue itself and its structural environments. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density w.r.t. χ i.", "model_B_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs). The first MLP generates embeddings for each residue, encoding the residue type, backbone dihedral angles, and local atom coordinates. We denote the embedding vector for the i-th residue as ei (i = 1, ..., n). The second MLP generates embeddings for each pair of residues, encoding the distance and relative position between two residues. We denote the pair embedding vector as zij (i, j = 1, ..., n). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings {ei} and pair embeddings {zij} into hidden representations {hi}. The hidden representation hi is aimed at capturing the information of both the i-th residue and its structural environment. It serves as an encoding of the conditions {aj, pj, Oj, ˜χj}nj=1 for the probability density w.r.t. χi.", "labels": ["Rewriting_medium"], "instruction": "Replace all mentions of amino acid by 'residue'. Reorder sentences in a more logical order when needed.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "id_pairing": 2431, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "coedit-xl", "original_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each  single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i ( i = 1 . . . n ). The other MLP for amino acid pairs mainly encodes the distance and  relative position between two amino acids and we denote a pair embedding vector as z ij ( i, j = 1 . . . n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings{ e i} and pair embeddings{ z ij} into hidden representations{ h i } . The hidden representation h i is aimed at capturing the informa- tion of both the i -th amino acid itself and its structural environments. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density w.r.t. χ i .", "reference_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each individual single residue and each pair of residues respectively. The MLP for single residues encodes the residue type, backbone dihedral angles, and local atom coordinates into a vector e i ( i = 1 . . . n ). The other MLP for residue pairs encodes the distance and the relative position between two residues. We denote a pair embedding vector as z ij ( i, j = 1 . . . n ). To transform the single embeddings e i and pair embeddings z ij into hidden representations h i , we use a self-attention-based network that is invariant to rotation and translation (Jumper et al., 2021). The hidden representation h i aims to capture both the information of the i -th residue itself and its structural environment. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density with respect to χ i .", "model_A_paragraph": "The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single residue and each pair of residues respectively. The MLP for single residue encodes the residue type, backbone dihedral angles, and local atom coordinates of each residue into a vector e i (i = 1... n). The other MLP for residue pairs mainly encodes the distance and relative position between two residues and we denote a pair embedding vector as z ij (i, j = 1... n). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings {e i} and pair embeddings {z ij} into hidden representations {h i}. The hidden representation h i is aimed at capturing the information of both the i-th residue itself and its structural environments. It serves as an encoding of the condition {a j, p j, O j, ˜χ j} nj=1 for the probability density w.r.t. χ i.", "model_B_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i ( i = 1... n ). The other MLP for amino acid pairs mainly encodes the distance and relative position between two amino acids and we denote a pair embedding vector as z ij ( i, j = 1.. n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings e i and pair embeddings z ij into hidden representations h i . The hidden representations h i  serve as an encoding of the condition  a j, p j", "labels": ["Rewriting_medium"], "instruction": "Replace all mentions of amino acid by 'residue'. Reorder sentences in a more logical order when needed.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "None", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.13", "id_pairing": 2432, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each  single amino acid and each pair of amino acids respectively. The MLP for single amino acid encodes the amino acid type, backbone dihedral angles, and local atom coordinates of each amino acid into a vector e i ( i = 1 . . . n ). The other MLP for amino acid pairs mainly encodes the distance and  relative position between two amino acids and we denote a pair embedding vector as z ij ( i, j = 1 . . . n ). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings{ e i} and pair embeddings{ z ij} into hidden representations{ h i } . The hidden representation h i is aimed at capturing the informa- tion of both the i -th amino acid itself and its structural environments. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density w.r.t. χ i .", "reference_paragraph": "Encoder Network The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each individual single residue and each pair of residues respectively. The MLP for single residues encodes the residue type, backbone dihedral angles, and local atom coordinates into a vector e i ( i = 1 . . . n ). The other MLP for residue pairs encodes the distance and the relative position between two residues. We denote a pair embedding vector as z ij ( i, j = 1 . . . n ). To transform the single embeddings e i and pair embeddings z ij into hidden representations h i , we use a self-attention-based network that is invariant to rotation and translation (Jumper et al., 2021). The hidden representation h i aims to capture both the information of the i -th residue itself and its structural environment. It serves as an encoding of the condition { a j , p j , O j , ˜ χ j } nj =1 for the probability density with respect to χ i .", "model_A_paragraph": "Encoder Network The encoder network begins with two multi-layer perceptrons (MLPs) that generate embeddings for each single residue and each pair of residues respectively. The MLP for single residue encodes the residue type, backbone dihedral angles, and local atom coordinates of each residue into a vector e i (i = 1 . . . n). The other MLP for residue pairs mainly encodes the distance and relative position between two residues, and we denote a pair embedding vector as z ij (i, j = 1 . . . n). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings {e i} and pair embeddings {z ij} into hidden representations {h i}. The hidden representation h i is aimed at capturing the information of both the i-th residue itself and its structural environments. It serves as an encoding of the condition {a j, p j, O j, ˜ χ j} nj=1 for the probability density with respect to χ i.", "model_B_paragraph": "The encoder network starts with two multi-layer perceptrons (MLPs) that generate embeddings for each single residue and each pair of residues respectively. The MLP for single residue encodes the residue type, backbone dihedral angles, and local atom coordinates of each residue into a vector e i (i = 1...n). The other MLP for residue pairs mainly encodes the distance and relative position between two residues and we denote a pair embedding vector as z ij (i, j = 1...n). Next, we use a self-attention-based network invariant to rotation and translation (Jumper et al., 2021) to transform the single embeddings {e i} and pair embeddings {z ij} into hidden representations {h i}. The hidden representation h i is aimed at capturing the information of both the i-th residue itself and its structural environments. Then, it serves as an encoding of the condition {a j, p j, O j, ˜ χ j}nj=1 for the probability density w.r.t. χ i.", "labels": ["Rewriting_medium"], "instruction": "Replace all mentions of amino acid by 'residue'. Reorder sentences in a more logical order when needed.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "None", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "id_pairing": 1480, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "coedit-xl", "original_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set  as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. This  also holds true for RecSim and Real RecSys , where the information of the most common category is sufﬁcient to select the same category’s items  to maximize CPR (e.g. Figure 6(c)). Therefore, we observe only 5 − 20% gains of AGILE over the ablations. To test  consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional  CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment:  task is to recommend pairs of associated items based on predeﬁned pairings. We reproduce the trend that AGILE > = ablations.", "reference_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the action set summary as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and enter lava accordingly to create shortcuts. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. This trend also holds for RecSim and Real RecSys , where the summary can ﬁnd the most common category and its items are then selected to maximize CPR (e.g., Figure 6(c)). Therefore, we observe only 5 − 20% gains of AGILE over the ablations. To test the consistency of results, we further evaluate two more RecSim tasks. (i) Direct CPR: the agent receives additional explicit CPR metric reward on top of click/noclick reward (Sec. B.3), and (ii) pairing environment: the task is to recommend pairs of associated items based on predeﬁned pairings (Sec. B.4). We reproduce the trend that AGILE > = ablations.", "model_A_paragraph": "Ablations: Figure 5 presents the ablation results on test actions. The grid world ablations utilize the summary of the action set as input, aggregated via different mechanisms, allowing them to identify available dig-lava skills and guide each action decision accordingly. In small action spaces with simple action relations, summary-ablations perform on par with AGILE, as observed in Figure 6(c), where the most common category's information is sufficient to select items to maximize CPR. Consequently, we observe only 5-20% gains of AGILE over the ablations. To assess the consistency of these results, we further evaluate AGILE and the ablations on two additional RecSim tasks: direct CPR, where the agent receives an additional CPR metric reward, and pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings.", "model_B_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. To test consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment: task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE > = ablations.", "labels": ["Rewriting_medium"], "instruction": "Improve the overall clarity of the paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "id_pairing": 1481, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set  as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. This  also holds true for RecSim and Real RecSys , where the information of the most common category is sufﬁcient to select the same category’s items  to maximize CPR (e.g. Figure 6(c)). Therefore, we observe only 5 − 20% gains of AGILE over the ablations. To test  consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional  CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment:  task is to recommend pairs of associated items based on predeﬁned pairings. We reproduce the trend that AGILE > = ablations.", "reference_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the action set summary as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and enter lava accordingly to create shortcuts. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. This trend also holds for RecSim and Real RecSys , where the summary can ﬁnd the most common category and its items are then selected to maximize CPR (e.g., Figure 6(c)). Therefore, we observe only 5 − 20% gains of AGILE over the ablations. To test the consistency of results, we further evaluate two more RecSim tasks. (i) Direct CPR: the agent receives additional explicit CPR metric reward on top of click/noclick reward (Sec. B.3), and (ii) pairing environment: the task is to recommend pairs of associated items based on predeﬁned pairings (Sec. B.4). We reproduce the trend that AGILE > = ablations.", "model_A_paragraph": "Ablations: Figure 5 illustrates the ablation results on test actions. Grid World: all ablations employ the summary of the action set as input, aggregated through different mechanisms. This allows them to determine which dig-lava skills are accessible and guide each action decision accordingly. In such small action spaces with simple action relationships, summary-ablations are comparable to AGILE. This trend is also observed in RecSim and Real RecSys, where the information about the most common category is sufficient to select items from the same category to maximize CPR (e.g., Figure 6(c)). Consequently, we observe only 5-20% improvements of AGILE over the ablations. To test the consistency of results, we further evaluate two more RecSim tasks: (i) Direct CPR, where the goal is still to maximize CPR, but the agent receives an additional CPR metric reward alongside the click/no-click reward (Sec B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend that AGILE outperforms or is equal to ablations.", "model_B_paragraph": "Ablations: Figure 5 presents the results of the ablation studies on test actions. In the Grid World, all ablations utilize the summary of the action set as input, aggregated through various mechanisms. This allows for the identification of which dig-lava skills are available, thereby guiding each action decision accordingly. In such small action spaces with simple action relationships, the summary-ablations perform comparably to AGILE. This observation also applies to RecSim and Real RecSys, where the information pertaining to the most common category is sufficient to select items from the same category to maximize the Click-Through Rate (CPR) (e.g., Figure 6(c)). Consequently, we notice only a 5% to 20% improvement of AGILE over the ablations. To assess the consistency of our results, we further evaluate two additional RecSim tasks: (i) Direct CPR, where the objective remains to maximize CPR, but the agent receives an additional CPR metric reward on top of the click/no-click reward (see Section B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on predefined pairings. We reproduce the trend showing that AGILE is greater than or equal to the ablations.", "labels": ["Rewriting_medium"], "instruction": "Improve the overall clarity of the paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "MXi6uEx-hp.rdZfFcGyf9.15", "id_pairing": 1482, "pararev_annot": "annot_2", "pararev_annotator": "annotator_03", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the summary of action set  as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and guide each action decision accordingly. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. This  also holds true for RecSim and Real RecSys , where the information of the most common category is sufﬁcient to select the same category’s items  to maximize CPR (e.g. Figure 6(c)). Therefore, we observe only 5 − 20% gains of AGILE over the ablations. To test  consistency of results, we further evaluate on two more RecSim tasks: (i) Direct CPR: task is still to maximize CPR, but agent receives additional  CPR metric reward on top of click/no-click reward (Sec B.3, and (ii) Pairing environment:  task is to recommend pairs of associated items based on predeﬁned pairings. We reproduce the trend that AGILE > = ablations.", "reference_paragraph": "Ablations : Figure 5 shows ablation results on test actions. Grid World : all ablations utilize the action set summary as input, aggregated via different mechanisms. Thus, they can identify which dig-lava skills are available and enter lava accordingly to create shortcuts. In such small action spaces with simple action relations, summary-ablations are on par with AGILE. This trend also holds for RecSim and Real RecSys , where the summary can ﬁnd the most common category and its items are then selected to maximize CPR (e.g., Figure 6(c)). Therefore, we observe only 5 − 20% gains of AGILE over the ablations. To test the consistency of results, we further evaluate two more RecSim tasks. (i) Direct CPR: the agent receives additional explicit CPR metric reward on top of click/noclick reward (Sec. B.3), and (ii) pairing environment: the task is to recommend pairs of associated items based on predeﬁned pairings (Sec. B.4). We reproduce the trend that AGILE > = ablations.", "model_A_paragraph": "Figure 5 illustrates the ablation results on test actions in Grid World. All ablations make use of the summarized action set as input, which is aggregated via different mechanisms. This allows the ablations to determine which dig-lava skills are available and make informed action decisions accordingly. In the context of small action spaces with simple action relations, summary-ablations perform equivalently to AGILE. Similar findings hold for RecSim and Real RecSys, where the information related to the most common category is sufficient to select items belonging to the same category and maximize CPR (as shown in Figure 6c). Consequently, gains for AGILE over the ablations range between 5-20%. To further assess consistency, we conducted evaluations on two additional RecSim tasks: (i) Direct CPR task, where the agent receives an additional CPR metric reward apart from the click/no-click reward (Detail B.3), and (ii) Pairing environment task, where the goal is to recommend pairs of associated items based on predefined pairings. These evaluations confirmed the trend of AGILE outperforming or being equal to the ablations.", "model_B_paragraph": "Ablations: Figure 5 presents the results of ablation studies on test actions. In the Grid World, all ablations utilize the summary of the action set as input, aggregated via different mechanisms, allowing them to identify available dig-lava skills and guide each action decision accordingly. In these small action spaces with simple action relations, the performance of summary-ablations is comparable to AGILE. Similarly, in RecSim and Real RecSys, the information about the most common category is sufficient to select items from the same category, maximizing CPR (e.g., Figure 6(c)). Consequently, we observe only 5-20% gains of AGILE over the ablations. To ensure the consistency of these results, we further evaluate AGILE on two additional RecSim tasks: (i) Direct CPR, where the agent receives an additional CPR metric reward on top of click/no-click reward (Sec B.3), and (ii) Pairing environment, where the task is to recommend pairs of associated items based on pre-defined pairings. Our results reproduce the trend that AGILE outperforms or is equal to the ablations.", "labels": ["Rewriting_medium"], "instruction": "Improve the overall clarity of the paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_medium": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "id_pairing": 2750, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "gpt-4o", "model_B": "gpt-4o-mini", "original_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no “simple” baselines. For example, a very simple  baseline  would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "reference_paragraph": "The baselines used to assess the performance of AutoML tools are often other AutoML tools or random search. A simple but perhaps more sensible baseline than random search would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is (Thornton et al., 2013), using the Exhaustive-Default (“Ex-def”) baseline which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_A_paragraph": "The baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no simple baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, it is difficult to understand how AutoML tools improve upon ad-hoc techniques and only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which involves taking the default parametrized model that performs best in cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_B_paragraph": "It is notable that the baselines used to assess the performance of AutoML tools are typically only other AutoML tools, rather than “simple” baselines. For example, a straightforward baseline could involve replicating the steps that a human data scientist might take, making this approach worthy of consideration as a baseline. Without such baselines, we do not gain insights into how AutoML tools advance beyond ad-hoc techniques, but rather only on how they compare to one another. To our knowledge, the only study that accounts for such baselines is Thornton et al. (2013), which utilizes the Exhaustive-Default (“Ex-def”) baseline, defined as selecting the default parametrized model that performs best in cross-validation. They also discuss a grid search, though this method may not be practically applicable.", "labels": ["Rewriting_light"], "instruction": "Edit some formulations to sound more neutral.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "id_pairing": 2751, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no “simple” baselines. For example, a very simple  baseline  would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "reference_paragraph": "The baselines used to assess the performance of AutoML tools are often other AutoML tools or random search. A simple but perhaps more sensible baseline than random search would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is (Thornton et al., 2013), using the Exhaustive-Default (“Ex-def”) baseline which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_A_paragraph": "Notably, the baselines employed to evaluate the performance of AutoML tools are often limited to other AutoML tools, with \"simple\" baselines being underrepresented. For instance, a straightforward baseline could involve mimicking the steps a human data scientist would take, which warrants consideration as a baseline. Without such baselines, it is unclear how AutoML tools improve upon ad-hoc techniques, as comparisons are only made relative to each other. To our knowledge, the only study that accounts for such baselines is Thornton et al. (2013), which utilizes the Exhaustive-Default (\"Ex-def\") baseline, involving the default parametrized model that performs best in cross-validation. They also discuss grid search, although it is not a practical approach.", "model_B_paragraph": "it is noteworthy that the baselines utilized to evaluate the effectiveness of AutoML tools often consist of other AutoML tools rather than \"simple\" alternatives. For instance, a fundamental baseline would be to emulate the actions of a human data scientist, enabling a fair comparison between such an approach and the AutoML tools. The absence of such baselines hinders our understanding of how AutoML tools surpass traditional techniques, offering merely a comparison of their relative performances. To our knowledge, Thornton et al. (2013) are the only researchers who have addressed this issue by employing the Exhaustive-Default (\"Ex-def\") baseline, which selects the best parametrized model through cross-validation. Additionally, they discuss the grid search technique, albeit infeasible in practice.", "labels": ["Rewriting_light"], "instruction": "Edit some formulations to sound more neutral.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "Rewriting_light": "B", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nkOpNqg-ip.OwJsIhe_p.00", "id_pairing": 2752, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no “simple” baselines. For example, a very simple  baseline  would be to imitate the steps a human data scientist would take, so that such an approach should be at least considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is Thornton et al. (2013) using the Exhaustive-Default (“Ex-def”) baseline, which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "reference_paragraph": "The baselines used to assess the performance of AutoML tools are often other AutoML tools or random search. A simple but perhaps more sensible baseline than random search would be to imitate the steps a human data scientist would take. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other. To our knowledge, the only work accounting for such baselines is (Thornton et al., 2013), using the Exhaustive-Default (“Ex-def”) baseline which is to take the default parametrized model that is best in a cross-validation. They also discuss a grid search, which is however not applicable in practice.", "model_A_paragraph": "Surprisingly, the baselines used to assess the performance of AutoML tools are typically only other AutoML tools but no \"simple\" baselines. For example, a very simple baseline would be to imitate the steps a human data scientist would take, so that such an approach should at least be considered as a baseline. Without such baselines, we do not learn how AutoML tools improve upon ad-hoc techniques but only how they compare relatively to each other.", "model_B_paragraph": "It is noteworthy that the baselines used to assess the performance of AutoML tools are typically limited to other AutoML tools, with little consideration given to simpler alternatives. For instance, a straightforward baseline could involve replicating the steps a human data scientist would take, which should at least be considered as a point of reference. Without such baselines, the evaluation focuses on relative comparisons between AutoML tools rather than their improvement upon ad-hoc techniques. To our knowledge, Thornton et al. (2013) is the only work that incorporates such baselines, including the Exhaustive-Default (“Ex-def”) baseline, which involves selecting the best default parametrized model through cross-validation. They also discuss a grid search, although its practical applicability is limited.", "labels": ["Rewriting_light"], "instruction": "Edit some formulations to sound more neutral.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "id_pairing": 4380, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences , while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which captures the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "reference_paragraph": "To address this challenge, the agent should consider the discrepancies between the human and its own model while generating explanations. In our prior work [7], we encapsulate such inconsistencies as model differences . An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which is used to produce the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation [7], [8].", "model_A_paragraph": "In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the user to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the user's expectation of the robot.", "model_B_paragraph": "Notably, our prior work (Chakraborti et al. 2017) has successfully identified and addressed the critical issue of inconsistencies, which we term model differences, arising from the discrepancies between human and robot models when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which captures the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "labels": ["Rewriting_medium"], "instruction": "Rewrite the first sentence to make it more convincing.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "None", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "id_pairing": 4381, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "gpt-4o-mini", "original_paragraph": "In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences , while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which captures the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "reference_paragraph": "To address this challenge, the agent should consider the discrepancies between the human and its own model while generating explanations. In our prior work [7], we encapsulate such inconsistencies as model differences . An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which is used to produce the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation [7], [8].", "model_A_paragraph": "Through our previous research (Chakraborti et al. 2017), we have demonstrated that inconsistencies can be attributed to model differences in the context of generating explanations for human-robot interactions. The reconciliation of such model differences is essential to ensure the human's updated mental model aligns with the robot's behavior, which is critical for the human's understanding and expectation. This process of adjusting mental models in response to observing a robot's behavior in the presence of model differences is referred to as model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "model_B_paragraph": "In our prior work (Chakraborti et al. 2017), we compellingly encapsulate inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which captures the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "labels": ["Rewriting_medium"], "instruction": "Rewrite the first sentence to make it more convincing.", "eval_annotation": {"relatedness_A": "Yes with additional modifications", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_medium": "A", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "ryESgXktV.BJ4dKdWmr.01", "id_pairing": 4382, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "In our prior work (Chakraborti et al. 2017), we encapsulate such inconsistencies as model differences , while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which captures the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "reference_paragraph": "To address this challenge, the agent should consider the discrepancies between the human and its own model while generating explanations. In our prior work [7], we encapsulate such inconsistencies as model differences . An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which is used to produce the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation [7], [8].", "model_A_paragraph": "In our seminal work (Chakraborti et al. 2017), we effectively encapsulate such inconsistencies as model differences, while considering the discrepancies between the human and its own model when generating explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot’s behavior would make sense in the updated model, which captures the human’s expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "model_B_paragraph": "In our pioneering study (Chakraborti et al. 2017), we successfully encapsulated inconsistencies arising from model differences, thereby acknowledging the discrepancies between human and model-generated explanations. An explanation then becomes a request to the human to adjust the model differences in his mind so that the robot's behavior would make sense in the updated model, which captures the human's expectation of the robot. The general decision-making process of an agent in the presence of such model differences is termed model reconciliation (Chakraborti et al. 2017; Zhang et al. 2017).", "labels": ["Rewriting_medium"], "instruction": "Rewrite the first sentence to make it more convincing.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "None", "extended_choice": "B"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "id_pairing": 4710, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "ImageNet dataset and can further ensemble them to obtain 60 . 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OTdistance only obtains 58 . 78 % accuracy. It is a limitation of the PLOT to still need few-shot datafor optimization, which cannot be directly applied in the zero-shot setting. We argue there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.", "reference_paragraph": "ImageNet dataset and can further ensemble them to obtain 60 . 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distanceonly obtains 58 . 78 % accuracy. We argue there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.", "model_A_paragraph": "In this section, we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy. We argue there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are close to the global feature and lack complementarity.", "model_B_paragraph": "In this section, we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy. We argue there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.", "labels": ["Content_deletion"], "instruction": "Remove any information that is not essential to the main points of the paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "SRquLaHRM4.vI2x5N-YHC.02", "id_pairing": 4711, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "coedit-xl", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "ImageNet dataset and can further ensemble them to obtain 60 . 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OTdistance only obtains 58 . 78 % accuracy. It is a limitation of the PLOT to still need few-shot datafor optimization, which cannot be directly applied in the zero-shot setting. We argue there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.", "reference_paragraph": "ImageNet dataset and can further ensemble them to obtain 60 . 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distanceonly obtains 58 . 78 % accuracy. We argue there are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.", "model_A_paragraph": "ImageNet dataset and can further ensemble them to obtain 60. 38 % top 1 accuracy. In this section,we replace the cosine distance between the global visual feature and prompts. However, without any learning, the OTdistance only obtains 58. 78 % top 1 accuracy. There are two reasons why the OT distance does not work without learning: 1) prompt engineering selects prompts based on the global feature and cosine distance, instead of OT distance with feature map; 2) all these selected prompts are closed to the global feature and lack the complementarity.", "model_B_paragraph": "We replace the cosine distance between the global visual feature and prompt ensemble with the OT distance between the feature map and all 7 prompts. However, without any learning, the OT distance only obtains 58.78% accuracy. This limitation suggests that PLOT still needs few-shot data for optimization and cannot be directly applied in the zero-shot setting. Two reasons explain why the OT distance does not work without learning: prompt engineering selects prompts based on the global feature and cosine distance, and the selected prompts lack complementarity.", "labels": ["Content_deletion"], "instruction": "Remove any information that is not essential to the main points of the paragraph.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "Both", "extended_choice": "Tie"}, "annotator_eval": "annotator_10"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "id_pairing": 4310, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Methods for predicting mutational effects for single proteins are either structure-based or sequencebased (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than  binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).", "reference_paragraph": "The prediction of mutational effects for single proteins can be achieved using either structure-based or sequence-based (evolution-based) approaches. Structure-based methods can be categorized into biophysical, statistical, and deep learning-based methods, which aim to predict the thermal stability or fitness of the protein rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Lei et al., 2023). Sequence-based methods rely on the mining of evolutionary history, done by performing statistics on multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021), or leveraging protein language models (PLMs) (Meier et al., 2021; Notin et al., 2022).", "model_A_paragraph": "Methods for predicting mutational effects in single proteins are categorized into structure-based and sequence-based (evolution-based) approaches. Structure-based methods include biophysical, statistical, and deep learning approaches, focusing on predicting protein thermal stability rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based predictions traditionally use statistics from multiple sequence alignments (MSAs) derived from large-scale databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent research indicates that protein language models (PLMs) can assess mutations without MSAs (Meier et al., 2021).", "model_B_paragraph": "Methods for predicting mutational effects in single proteins can be categorized as structure-based or sequence-based (evolution-based). Structure-based approaches, including biophysical, statistical, and deep learning-based methods, focus on predicting protein thermal stability or fitness (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, on the other hand, exploit evolutionary history by analyzing multiple sequence alignments (MSAs) or, more recently, using protein language models (PLMs) trained on large sequence databases to evaluate mutations (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022; Meier et al., 2021).", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make this paragraph shorter and more fitted to academic style.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "Both", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "id_pairing": 4311, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "coedit-xl", "original_paragraph": "Methods for predicting mutational effects for single proteins are either structure-based or sequencebased (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than  binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).", "reference_paragraph": "The prediction of mutational effects for single proteins can be achieved using either structure-based or sequence-based (evolution-based) approaches. Structure-based methods can be categorized into biophysical, statistical, and deep learning-based methods, which aim to predict the thermal stability or fitness of the protein rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Lei et al., 2023). Sequence-based methods rely on the mining of evolutionary history, done by performing statistics on multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021), or leveraging protein language models (PLMs) (Meier et al., 2021; Notin et al., 2022).", "model_A_paragraph": "Methods for predicting mutational effects in single proteins can be categorized as structure-based or sequence-based. Structure-based approaches include biophysical, statistical, and deep learning methods, focusing on predicting thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based predictions leverage evolutionary history, typically through statistical analyses of multiple sequence alignments (MSAs) derived from large-scale databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent research indicates that protein language models (PLMs) trained on extensive sequence data can assess mutations without MSAs (Meier et al., 2021).", "model_B_paragraph": "Methods for predicting mutational effects for single proteins are either structure-based or sequence-based (evolution-based).", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make this paragraph shorter and more fitted to academic style.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "A", "Rewriting_medium": "A", "extended_choice": "A"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.09", "id_pairing": 4312, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "Methods for predicting mutational effects for single proteins are either structure-based or sequencebased (evolution-based). Structure-based approaches can also be divided into biophysical methods, statistical methods, and deep learning-based methods. They aim at predicting thermal stability or fitness of the protein rather than  binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). The mutational effects of single proteins can also be predicted using only sequences via mining its evolutionary history. Traditionally, this is done by performing statistics on multiple sequence alignments (MSAs), which are constructed by searching from largescale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent studies show that protein language models (PLMs)trained on large sequence databases are capable of evaluating mutations without MSAs (Meier et al., 2021).", "reference_paragraph": "The prediction of mutational effects for single proteins can be achieved using either structure-based or sequence-based (evolution-based) approaches. Structure-based methods can be categorized into biophysical, statistical, and deep learning-based methods, which aim to predict the thermal stability or fitness of the protein rather than the binding free energy between proteins (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017; Lei et al., 2023). Sequence-based methods rely on the mining of evolutionary history, done by performing statistics on multiple sequence alignments (MSAs) constructed from large-scale sequence databases (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021), or leveraging protein language models (PLMs) (Meier et al., 2021; Notin et al., 2022).", "model_A_paragraph": "Methods for predicting mutational effects on single proteins can be categorized into structure-based and sequence-based approaches. Structure-based methods, including biophysical, statistical, and deep learning-based methods, aim to predict thermal stability or fitness rather than binding free energy (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods, which involve mining evolutionary history, can also be used to predict mutational effects. Recent studies have shown that protein language models trained on large sequence databases can evaluate mutations without the need for multiple sequence alignments (Meier et al., 2021).", "model_B_paragraph": "Single proteins' mutational effects can be predicted using structure-based or sequence-based approaches. Structural methods, including biophysical, statistical, and deep learning-based techniques, focus on predicting thermal stability or protein fitness (Schymkowitz et al., 2005; Park et al., 2016; Alford et al., 2017). Sequence-based methods predict mutational effects via analyzing a protein's evolutionary history through multiple sequence alignments (Hopf et al., 2017; Riesselman et al., 2018; Rao et al., 2021; Luo et al., 2021; Frazer et al., 2021; Notin et al., 2022). Recent innovations involve the utilization of protein language models (PLMs) trained on extensive sequence databases to assess mutations without the need for MSAs (Meier et al., 2021).", "labels": ["Concision", "Rewriting_medium"], "instruction": "Make this paragraph shorter and more fitted to academic style.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Concision": "B", "Rewriting_medium": "B", "extended_choice": "B"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "id_pairing": 4630, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "gpt-4o-mini", "model_B": "coedit-xl", "original_paragraph": "In this section we show that neural networks progressively lose their ability to quickly ﬁt new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We ﬁnd that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-ﬁtting capacity measure which is efﬁcient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We ﬁnd evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "reference_paragraph": "In this section we demonstrate conditions under which neural networks progressively lose their ability to quickly ﬁt new targets when trained on sequences of prediction tasks including but not limited to those found in value-based RL. We ﬁnd that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-ﬁtting capacity measure which is efﬁcient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We ﬁnd evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "model_A_paragraph": "In this section, we demonstrate that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-fitting capacity measure which is efficient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We find evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "model_B_paragraph": "In this section we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks, including but not limited to those found in value-based RL. We find that this loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero.", "labels": ["Rewriting_light", "Content_deletion"], "instruction": "Rewrite the first sentence. Remove the example to make it shorter.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "id_pairing": 4631, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "In this section we show that neural networks progressively lose their ability to quickly ﬁt new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We ﬁnd that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-ﬁtting capacity measure which is efﬁcient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We ﬁnd evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "reference_paragraph": "In this section we demonstrate conditions under which neural networks progressively lose their ability to quickly ﬁt new targets when trained on sequences of prediction tasks including but not limited to those found in value-based RL. We ﬁnd that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-ﬁtting capacity measure which is efﬁcient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We ﬁnd evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "model_A_paragraph": "This section investigates the degradation of neural networks' ability to quickly fit new targets when trained on sequential prediction tasks. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-fitting capacity measure which is efficient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We find evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "model_B_paragraph": "In this section, we demonstrate that neural networks gradually lose their capacity to effectively learn new targets in sequential prediction tasks, such as those in value-based RL. Capacity loss is particularly significant in sparse prediction tasks, where the majority of target values are zero. To further explore the impact of extreme capacity loss on performance, we introduce an efficient version of the target-fitting capacity measure, which intuitively assesses a representation's ability to linearly disentangle states. Our findings suggest that agents with greater capacity, as measured by this metric, exhibit better performance in challenging Atari environments where human parity is not attained, while representations that collapse according to this metric show no learning progress.", "labels": ["Rewriting_light", "Content_deletion"], "instruction": "Rewrite the first sentence. Remove the example to make it shorter.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "jzQGmT-R1q.ugUt9B3XaO.00", "id_pairing": 4632, "pararev_annot": "annot_1", "pararev_annotator": "annotator_04", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "In this section we show that neural networks progressively lose their ability to quickly ﬁt new targets when trained on sequential prediction tasks (i.e. settings in which the agent must solve a regression problem that iteratively changes over the course of training) including but not limited to those found in value-based RL. We ﬁnd that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-ﬁtting capacity measure which is efﬁcient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We ﬁnd evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "reference_paragraph": "In this section we demonstrate conditions under which neural networks progressively lose their ability to quickly ﬁt new targets when trained on sequences of prediction tasks including but not limited to those found in value-based RL. We ﬁnd that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-ﬁtting capacity measure which is efﬁcient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We ﬁnd evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "model_A_paragraph": "In this section, we show that neural networks progressively lose their ability to quickly fit new targets when trained on sequential prediction tasks. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many of the target values the agent seeks to predict are zero. To study the effect of extreme capacity loss on performance in greater depth, we present a special case of the target-fitting capacity measure which is efficient to compute and has the intuitive interpretation of measuring the ability of the representation to linearly disentangle states. We find evidence that agents which have greater capacity according to this metric tend to achieve better performance in challenging environments from the Atari suite where agents fail to match human performance, and that those suffering from representation collapse according to this metric fail to make any learning progress at all.", "model_B_paragraph": "In this section, we demonstrate that neural networks' ability to quickly fit new targets deteriorates when trained on sequential prediction tasks, including those in value-based RL. We find that capacity loss is particularly pronounced in sparse prediction tasks, where many target values are zero.", "labels": ["Rewriting_light", "Content_deletion"], "instruction": "Rewrite the first sentence. Remove the example to make it shorter.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes with additional modifications", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "id_pairing": 3220, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "gpt-4o", "original_paragraph": "Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "reference_paragraph": "A pointing operation for an edge target exploits the fact that the cur- sor stops at the edge of the screen to complete the pointing without precise control. However, pushing-edge behavior, i.e., pushing the cursor to the edge of the screen, increases the distance traveled by the mouse, and this increases the movement time. Yamanaka [28] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "model_A_paragraph": "The pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen, enabling completion of the pointing task without requiring precise control. However, the behavior of pushing the cursor to the edge of the screen—referred to as pushing-edge—results in an increased distance traveled by the mouse, which in turn raises the movement time. To quantify this phenomenon, Yamanaka [25] defined Path Efficiency (PE) as a metric to evaluate the efficiency of cursor movements (Eq. 7).", "model_B_paragraph": "The pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen, allowing completion of the pointing without precise control. However, the pushing-edge behavior, which involves pushing the cursor to the edge of the screen, increases the distance traveled by the mouse and thereby increases the movement time. To address this, Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Improve the linking between ideas to make the paragraph more precise and readable.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "id_pairing": 3221, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "coedit-xl", "original_paragraph": "Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "reference_paragraph": "A pointing operation for an edge target exploits the fact that the cur- sor stops at the edge of the screen to complete the pointing without precise control. However, pushing-edge behavior, i.e., pushing the cursor to the edge of the screen, increases the distance traveled by the mouse, and this increases the movement time. Yamanaka [28] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "model_A_paragraph": "During a pointing operation to the edge target, the cursor stops at the edge of the screen, allowing the operation to be completed without the need for precise control. However, pushing the cursor to the edge of the screen (pushing-edge behavior) increases the distance traveled by the mouse, thereby resulting in longer movement times. According to Yamanaka [25], Path Efficiency (PE) is used to measure the efficiency of cursor movements (Eq. 7).", "model_B_paragraph": "Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Improve the linking between ideas to make the paragraph more precise and readable.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_medium": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "hegI87bI5S.fL6Q48sfx8.07", "id_pairing": 3222, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control. However, pushing-edge (pushing the cursor to the edge of the screen) behavior increases the distance traveled by the mouse, thereby increasing the movement time. Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "reference_paragraph": "A pointing operation for an edge target exploits the fact that the cur- sor stops at the edge of the screen to complete the pointing without precise control. However, pushing-edge behavior, i.e., pushing the cursor to the edge of the screen, increases the distance traveled by the mouse, and this increases the movement time. Yamanaka [28] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "model_A_paragraph": "Pointing operation to the edge target takes advantage of the cursor stopping at the edge of the screen to complete the pointing without precise control, which is known as pushing-edge behavior. However, this behavior increases the distance traveled by the mouse, thereby increasing the movement time. To quantify this effect, Yamanaka [25] defined PE (Path Efficiency) to calculate the efficiency of the cursor movements (Eq. 7).", "model_B_paragraph": "Pointing operation to the edge target leverages the cursor's tendency to stop at the edge of the screen, allowing for completion without precise control. However, this pushing-edge behavior, where the cursor is pushed to the edge of the screen, increases the distance traveled by the mouse, thereby prolonging the movement time. This observation is supported by Yamanaka's [25] definition of PE (Path Efficiency), which calculates the efficiency of cursor movements (Eq. 7), providing a quantitative framework for evaluating the effectiveness of edge-target pointing operations.", "labels": ["Rewriting_medium", "Rewriting_light"], "instruction": "Improve the linking between ideas to make the paragraph more precise and readable.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_medium": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "id_pairing": 1570, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o", "model_B": "Meta-Llama-3-8B-Instruct", "original_paragraph": "In summary, our contributions include: 1) proposing a novel ( σ, δ ) -measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that  alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.", "reference_paragraph": "In summary, our contributions include: 1) proposing a novel ( σ, δ ) -measure to quantify data augmentation; 2) presenting a theoretical framework for contrastive SSL that highlights alignment, divergence, and concentration as key factors for generalization ability; provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy alignment and divergence; 4) showing a strong correlation between downstream performance and concentration of augmented data.", "model_A_paragraph": "In summary, our contributions include: 1) proposing a novel (σ, δ)-measure to quantify data augmentation; 2) introducing a theoretical framework for contrastive Self-Supervised Learning (SSL), which suggests that alignment, divergence, and concentration are key factors influencing generalization ability; 3) theoretically verifying that not only the InfoNCE loss, but also the cross-correlation loss, satisfies alignment and divergence; 4) empirically demonstrating that concentration with respect to the proposed augmented distance is highly related to downstream performance.", "model_B_paragraph": "In summary, our contributions encompass: 1) introducing a novel (σ, δ)-measure to quantify data augmentation; 2) developing a theoretical framework for contrastive self-supervised learning, which posits that alignment, divergence, and concentration are pivotal factors influencing generalization ability; 3) rigorously verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence conditions; 4) empirically demonstrating that the concentration with respect to the proposed augmented distance is strongly correlated with downstream performance.", "labels": ["Rewriting_light"], "instruction": "Improve english in this text.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "id_pairing": 1571, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "Meta-Llama-3-70B-Instruct", "model_B": "Mistral-7B-Instruct-v0.2", "original_paragraph": "In summary, our contributions include: 1) proposing a novel ( σ, δ ) -measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that  alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.", "reference_paragraph": "In summary, our contributions include: 1) proposing a novel ( σ, δ ) -measure to quantify data augmentation; 2) presenting a theoretical framework for contrastive SSL that highlights alignment, divergence, and concentration as key factors for generalization ability; provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy alignment and divergence; 4) showing a strong correlation between downstream performance and concentration of augmented data.", "model_A_paragraph": "In summary, our contributions are threefold: 1) we propose a novel (σ, δ) -measure to quantify data augmentation; 2) we develop a theoretical framework for contrastive self-supervised learning, which identifies alignment, divergence, and concentration as key factors influencing generalization ability; 3) we provide theoretical verification that both the InfoNCE loss and the cross-correlation loss satisfy the alignment and divergence conditions; 4) our empirical results demonstrate a strong correlation between concentration with respect to the proposed augmented distance and downstream performance.", "model_B_paragraph": "In summary, our contributions are as follows: 1) we propose a novel (σ, δ) -measure for quantifying data augmentation; 2) we present a theoretical framework for contrastive self-supervised learning (SSL), emphasizing the importance of alignment, divergence, and concentration for generalization ability; 3) we prove that both the InfoNCE loss and the cross-correlation loss satisfy alignment and divergence properties; 4) empirically, we demonstrate a strong correlation between concentration relative to the proposed augmented distance and downstream performance.", "labels": ["Rewriting_light"], "instruction": "Improve english in this text.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "extended_choice": "B"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "9wfZbn73om.FhHH15YtKt.01", "id_pairing": 1572, "pararev_annot": "annot_2", "pararev_annotator": "annotator_07", "model_A": "gpt-4o-mini", "model_B": "coedit-xl", "original_paragraph": "In summary, our contributions include: 1) proposing a novel ( σ, δ ) -measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that  alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.", "reference_paragraph": "In summary, our contributions include: 1) proposing a novel ( σ, δ ) -measure to quantify data augmentation; 2) presenting a theoretical framework for contrastive SSL that highlights alignment, divergence, and concentration as key factors for generalization ability; provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy alignment and divergence; 4) showing a strong correlation between downstream performance and concentration of augmented data.", "model_A_paragraph": "In summary, our contributions include: 1) proposing a novel (σ, δ)-measure to quantify data augmentation; 2) developing a theoretical framework for contrastive SSL, which posits that alignment, divergence, and concentration are key factors influencing generalization ability; 3) rigorously demonstrating that both the InfoNCE loss and the cross-correlation loss satisfy the criteria of alignment and divergence; 4) empirically illustrating that concentration concerning the proposed augmented distance is closely related to downstream performance.", "model_B_paragraph": "In summary, our contributions include: 1) proposing a novel (,  )-measure to quantify the data augmentation; 2) proposing a theoretical framework for contrastive SSL, which suggests that alignment, divergence, and concentration are key factors of generalization ability; 3) provably verifying that not only the InfoNCE loss but also the cross-correlation loss satisfy the alignment and divergence; 4) empirically showing that the concentration w.r.t. the proposed augmented distance is highly related to the downstream performance.", "labels": ["Rewriting_light"], "instruction": "Improve english in this text.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Rewriting_light": "A", "extended_choice": "A"}, "annotator_eval": "annotator_09"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "id_pairing": 2980, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Mistral-7B-Instruct-v0.2", "model_B": "coedit-xl", "original_paragraph": "Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicatea time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered. The calendar should have daily summaries. These summaries should be used to give an overview of the list of medications to be administered every day. They should only contain the name of the medication. Their design should be such that the user can decide whether to add or remove them from the display. When dealing with conflicts, emphasis should be placed on theposition of the conflicting entries and not the connectors. If present, lines that connect conflicting entries should have less emphasis. On-calendar conflict representation should not be used as the main indication of an error after a rescheduling activity. The user shouldinstead be notified of the impending conflict beforehand. Participants preferred that normal, dismissible error messages be displayed and show the full information regarding the conflicts being introduced by the action. When rescheduling medication entries, cells that are either safe or unsafe should be communicated to the user by highlighting them using a color that implies either success or warning (e.g., green for the former and yellow for the latter). Although some participants felt that the design should not allow them to schedule an entry in the space that is likely to cause a conflict, there might be situations where this possibility would be desirable. The user should, in this case, be guided on possible moves that will resolve the conflict. This can be done by shading or using an outline for all the cells to which an entry may be rescheduled to resolve the conflict, and letting users configure the amount of warnings and error messages they want to receive.", "reference_paragraph": "Medication entries should have markers that communicate the times that their reminders will be triggered. The markers should not communicate time ranges but points in time when reminders are triggered. The calendar should have daily summaries of the list of medications to be administered each day. These summaries should only contain the name of the medication and users should be able to show or hide them. Medication conflicts should be emphasized on the conflicting entries rather than on the connectors. The user should be notified of a newly created conflict upon rescheduling an entry, preferably via dismissible error messages that describe the conflict. When rescheduling medication entries, cells that are either safe or unsafe should be highlighted to the user to guide their action. Although some participants felt that the design should not allow them to schedule an entry in the space that is likely to cause a conflict, there might be situations where this possibility is unavoidable. The user should, in this case, be guided on possible moves that will resolve the conflict. This can be done by shading or using an outline for all the cells to which an entry may be rescheduled to resolve the conflict, and letting users configure the amount of warnings and error messages they want to receive.", "model_A_paragraph": "Medication entries require a marker indicating the exact time for reminder triggers. Calendars should display daily summaries, which only show medication names. Conflicting entries should be represented by position, with connector lines of lesser emphasis. Error messages should be normal and informative about conflicts. Rescheduling activities should notify users of impending conflicts beforehand, and safe or unsafe cells should be highlighted for user convenience. Some participants suggested preventing scheduling in conflict areas, but this flexibility may be necessary in certain situations. Users should then be guided on possible resolutions.", "model_B_paragraph": "Medication entries should have a marker that communicates the time that their reminder will be triggered. The reminder should not communicate a time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered.", "labels": ["Content_deletion", "Concision"], "instruction": "Heavily remove details from this paragraph to make it more concise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "No", "acceptable": "A only", "correctness_A": true, "correctness_B": false, "preference": "A", "Concision": "A", "extended_choice": "A"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "id_pairing": 2981, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "Meta-Llama-3-8B-Instruct", "model_B": "Meta-Llama-3-70B-Instruct", "original_paragraph": "Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicatea time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered. The calendar should have daily summaries. These summaries should be used to give an overview of the list of medications to be administered every day. They should only contain the name of the medication. Their design should be such that the user can decide whether to add or remove them from the display. When dealing with conflicts, emphasis should be placed on theposition of the conflicting entries and not the connectors. If present, lines that connect conflicting entries should have less emphasis. On-calendar conflict representation should not be used as the main indication of an error after a rescheduling activity. The user shouldinstead be notified of the impending conflict beforehand. Participants preferred that normal, dismissible error messages be displayed and show the full information regarding the conflicts being introduced by the action. When rescheduling medication entries, cells that are either safe or unsafe should be communicated to the user by highlighting them using a color that implies either success or warning (e.g., green for the former and yellow for the latter). Although some participants felt that the design should not allow them to schedule an entry in the space that is likely to cause a conflict, there might be situations where this possibility would be desirable. The user should, in this case, be guided on possible moves that will resolve the conflict. This can be done by shading or using an outline for all the cells to which an entry may be rescheduled to resolve the conflict, and letting users configure the amount of warnings and error messages they want to receive.", "reference_paragraph": "Medication entries should have markers that communicate the times that their reminders will be triggered. The markers should not communicate time ranges but points in time when reminders are triggered. The calendar should have daily summaries of the list of medications to be administered each day. These summaries should only contain the name of the medication and users should be able to show or hide them. Medication conflicts should be emphasized on the conflicting entries rather than on the connectors. The user should be notified of a newly created conflict upon rescheduling an entry, preferably via dismissible error messages that describe the conflict. When rescheduling medication entries, cells that are either safe or unsafe should be highlighted to the user to guide their action. Although some participants felt that the design should not allow them to schedule an entry in the space that is likely to cause a conflict, there might be situations where this possibility is unavoidable. The user should, in this case, be guided on possible moves that will resolve the conflict. This can be done by shading or using an outline for all the cells to which an entry may be rescheduled to resolve the conflict, and letting users configure the amount of warnings and error messages they want to receive.", "model_A_paragraph": "Medication entries should have a marker indicating the exact time of reminder trigger. The calendar should include daily summaries with medication names, allowing users to add or remove them. In conflicts, emphasis should be on the conflicting entries' positions, with less emphasis on connectors. The user should be notified of impending conflicts beforehand, and normal, dismissible error messages should be displayed with full conflict information. When rescheduling, cells with potential conflicts should be highlighted with warning colors, and users should be guided on possible moves to resolve conflicts.", "model_B_paragraph": "Medication entries should have a marker indicating the exact time of reminder triggers. The calendar should display daily summaries of medications to be administered, with users able to add or remove them. When dealing with conflicts, emphasis should be on the conflicting entries' positions, not connectors. Users should be notified of impending conflicts beforehand, with dismissible error messages displaying full conflict information. Rescheduling medication entries should highlight safe or unsafe cells using success or warning colors, guiding users on possible moves to resolve conflicts.", "labels": ["Content_deletion", "Concision"], "instruction": "Heavily remove details from this paragraph to make it more concise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "Both", "extended_choice": "B"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "u9NaukzyJ-.hh0KECXQLv.20", "id_pairing": 2982, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "gpt-4o-mini", "model_B": "gpt-4o", "original_paragraph": "Medication entries should have a marker that communicates the time that their reminder will be triggered. The marker should not communicatea time range (as we used in all three designs), but a point in time, such as a minute, when the reminder is triggered. The calendar should have daily summaries. These summaries should be used to give an overview of the list of medications to be administered every day. They should only contain the name of the medication. Their design should be such that the user can decide whether to add or remove them from the display. When dealing with conflicts, emphasis should be placed on theposition of the conflicting entries and not the connectors. If present, lines that connect conflicting entries should have less emphasis. On-calendar conflict representation should not be used as the main indication of an error after a rescheduling activity. The user shouldinstead be notified of the impending conflict beforehand. Participants preferred that normal, dismissible error messages be displayed and show the full information regarding the conflicts being introduced by the action. When rescheduling medication entries, cells that are either safe or unsafe should be communicated to the user by highlighting them using a color that implies either success or warning (e.g., green for the former and yellow for the latter). Although some participants felt that the design should not allow them to schedule an entry in the space that is likely to cause a conflict, there might be situations where this possibility would be desirable. The user should, in this case, be guided on possible moves that will resolve the conflict. This can be done by shading or using an outline for all the cells to which an entry may be rescheduled to resolve the conflict, and letting users configure the amount of warnings and error messages they want to receive.", "reference_paragraph": "Medication entries should have markers that communicate the times that their reminders will be triggered. The markers should not communicate time ranges but points in time when reminders are triggered. The calendar should have daily summaries of the list of medications to be administered each day. These summaries should only contain the name of the medication and users should be able to show or hide them. Medication conflicts should be emphasized on the conflicting entries rather than on the connectors. The user should be notified of a newly created conflict upon rescheduling an entry, preferably via dismissible error messages that describe the conflict. When rescheduling medication entries, cells that are either safe or unsafe should be highlighted to the user to guide their action. Although some participants felt that the design should not allow them to schedule an entry in the space that is likely to cause a conflict, there might be situations where this possibility is unavoidable. The user should, in this case, be guided on possible moves that will resolve the conflict. This can be done by shading or using an outline for all the cells to which an entry may be rescheduled to resolve the conflict, and letting users configure the amount of warnings and error messages they want to receive.", "model_A_paragraph": "Medication entries should have a marker indicating a specific time for reminder activation, rather than a time range. The calendar should feature daily summaries that list medication names and allow users to add or remove them. Conflicting entries should emphasize their position rather than connectors, with less focus on connecting lines. On-calendar conflict representation should not be the main error indication after rescheduling; users should be informed of conflicts beforehand. Participants preferred normal, dismissible error messages that provide full conflict details. When rescheduling, safe or unsafe cells should be highlighted in colors indicating success (green) or warning (yellow). While some participants argued against scheduling in conflict-prone spaces, guidance for conflict resolution should be provided through shading or outlining potential rescheduling options, with user control over warning and error message preferences.", "model_B_paragraph": "Medication entries should have a marker indicating the exact time for reminders. Daily calendar summaries should list medication names, allowing users to add or remove them as needed. Conflict emphasis should be on entry positions, not connectors. Users should be notified of conflicts before rescheduling, with clear error messages displayed. Safe and unsafe schedule cells should be highlighted in different colors. Users should have options to manage warnings and error messages, and be guided on resolving conflicts by shading possible reschedule options.", "labels": ["Content_deletion", "Concision"], "instruction": "Heavily remove details from this paragraph to make it more concise.", "eval_annotation": {"relatedness_A": "Yes strictly", "relatedness_B": "Yes strictly", "acceptable": "Both", "correctness_A": true, "correctness_B": true, "preference": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_03"}
{"id_paragraph": "nCTSF9BQJ.DGhBYSP_sR.21", "id_pairing": 2290, "pararev_annot": "annot_1", "pararev_annotator": "annotator_03", "model_A": "coedit-xl", "model_B": "gpt-4o-mini", "original_paragraph": "Sequence-based models do not  predict ∆∆ G accurately for protein-protein binding in accordance with the discussion in Section 2.2. Figure 3 plots the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.", "reference_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding, as discussed in Section 2.2. Figure 3 shows the distribution of per-complex correlation coefficients. Please refer to Section B of the appendix for more results and discussion.", "model_A_paragraph": "Sequence-based models do not predict  G accurately for protein-protein binding as discussed in Section 2.2. Please refer to Section B of the appendix for more results and discussion.", "model_B_paragraph": "Sequence-based models do not accurately predict ∆∆ G for protein-protein binding, as discussed in Section 2.2. Figure 3 shows the distribution of correlation coefficients for each complex. For more results and discussion, please see Section B of the appendix.", "labels": ["Rewriting_light", "Concision"], "instruction": "Simplify the English of this paragraph.", "eval_annotation": {"relatedness_A": "No", "relatedness_B": "Yes strictly", "acceptable": "B only", "correctness_A": false, "correctness_B": true, "preference": "B", "Rewriting_light": "B", "Concision": "B", "extended_choice": "B"}, "annotator_eval": "annotator_03"}
